{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network Example\n",
    "\n",
    "Build a deep convolutional generative adversarial network (DCGAN) to generate digit images from a noise distribution with TensorFlow v2.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Overview\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/45e147fc9dfcf6a8e5df2c9b985078258b9974e3/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313030302f312a33394e6e6e695f6e685044614c7539416e544c6f57772e706e67\" alt=\"dcgan\" style=\"width: 1000px;\"/>\n",
    "\n",
    "References:\n",
    "- [Unsupervised representation learning with deep convolutional generative adversarial networks](https://arxiv.org/pdf/1511.06434). A Radford, L Metz, S Chintala, 2016.\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html). X Glorot, Y Bengio. Aistats 9, 249-256\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). Sergey Ioffe, Christian Szegedy. 2015.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 255. \n",
    "\n",
    "In this example, each image will be converted to float32 and normalized from [0, 255] to [0, 1].\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset parameters.\n",
    "num_features = 784 # data features (img shape: 28*28).\n",
    "\n",
    "# Training parameters.\n",
    "lr_generator = 0.0002\n",
    "lr_discriminator = 0.0002\n",
    "training_steps = 20000\n",
    "batch_size = 128\n",
    "display_step = 500\n",
    "\n",
    "# Network parameters.\n",
    "noise_dim = 100 # Noise data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MNIST data.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class Generator(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = layers.Dense(7 * 7 * 128)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2tr1 = layers.Conv2DTranspose(64, 5, strides=2, padding='SAME')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv2tr2 = layers.Conv2DTranspose(1, 5, strides=2, padding='SAME')\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x, training=is_training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        # Reshape to a 4-D array of images: (batch, height, width, channels)\n",
    "        # New shape: (batch, 7, 7, 128)\n",
    "        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n",
    "        # Deconvolution, image shape: (batch, 14, 14, 64)\n",
    "        x = self.conv2tr1(x)\n",
    "        x = self.bn2(x, training=is_training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        # Deconvolution, image shape: (batch, 28, 28, 1)\n",
    "        x = self.conv2tr2(x)\n",
    "        x = tf.nn.tanh(x)\n",
    "        return x\n",
    "\n",
    "# Generator Network\n",
    "# Input: Noise, Output: Image\n",
    "# Note that batch normalization has different behavior at training and inference time,\n",
    "# we then use a placeholder to indicates the layer if we are training or not.\n",
    "class Discriminator(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(64, 5, strides=2, padding='SAME')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(128, 5, strides=2, padding='SAME')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(1024)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.fc2 = layers.Dense(2)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=is_training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=is_training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn3(x, training=is_training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Build neural network model.\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses.\n",
    "def generator_loss(reconstructed_image):\n",
    "    gen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=reconstructed_image, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "    return gen_loss\n",
    "\n",
    "def discriminator_loss(disc_fake, disc_real):\n",
    "    disc_loss_real = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=disc_real, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "    disc_loss_fake = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=disc_fake, labels=tf.zeros([batch_size], dtype=tf.int32)))\n",
    "    return disc_loss_real + disc_loss_fake\n",
    "\n",
    "# Optimizers.\n",
    "optimizer_gen = tf.optimizers.Adam(learning_rate=lr_generator)#, beta_1=0.5, beta_2=0.999)\n",
    "optimizer_disc = tf.optimizers.Adam(learning_rate=lr_discriminator)#, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. Inputs: real image and noise.\n",
    "def run_optimization(real_images):\n",
    "    \n",
    "    # Rescale to [-1, 1], the input range of the discriminator\n",
    "    real_images = real_images * 2. - 1.\n",
    "\n",
    "    # Generate noise.\n",
    "    noise = np.random.normal(-1., 1., size=[batch_size, noise_dim]).astype(np.float32)\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "            \n",
    "        fake_images = generator(noise, is_training=True)\n",
    "        disc_fake = discriminator(fake_images, is_training=True)\n",
    "        disc_real = discriminator(real_images, is_training=True)\n",
    "\n",
    "        disc_loss = discriminator_loss(disc_fake, disc_real)\n",
    "            \n",
    "    # Training Variables for each optimizer\n",
    "    gradients_disc = g.gradient(disc_loss,  discriminator.trainable_variables)\n",
    "    optimizer_disc.apply_gradients(zip(gradients_disc,  discriminator.trainable_variables))\n",
    "    \n",
    "    # Generate noise.\n",
    "    noise = np.random.normal(-1., 1., size=[batch_size, noise_dim]).astype(np.float32)\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "            \n",
    "        fake_images = generator(noise, is_training=True)\n",
    "        disc_fake = discriminator(fake_images, is_training=True)\n",
    "\n",
    "        gen_loss = generator_loss(disc_fake)\n",
    "            \n",
    "    gradients_gen = g.gradient(gen_loss, generator.trainable_variables)\n",
    "    optimizer_gen.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: gen_loss: 0.694535, disc_loss: 1.403878\n",
      "step: 500, gen_loss: 2.154825, disc_loss: 0.429040\n",
      "step: 1000, gen_loss: 2.103464, disc_loss: 0.502638\n",
      "step: 1500, gen_loss: 2.282369, disc_loss: 0.572065\n",
      "step: 2000, gen_loss: 2.711531, disc_loss: 0.341791\n",
      "step: 2500, gen_loss: 2.835576, disc_loss: 0.322356\n",
      "step: 3000, gen_loss: 2.970127, disc_loss: 0.275483\n",
      "step: 3500, gen_loss: 2.836321, disc_loss: 0.190680\n",
      "step: 4000, gen_loss: 2.892855, disc_loss: 0.337681\n",
      "step: 4500, gen_loss: 2.948962, disc_loss: 0.329322\n",
      "step: 5000, gen_loss: 3.799061, disc_loss: 0.327288\n",
      "step: 5500, gen_loss: 4.090328, disc_loss: 0.274685\n",
      "step: 6000, gen_loss: 4.343777, disc_loss: 0.155223\n",
      "step: 6500, gen_loss: 3.806556, disc_loss: 0.155855\n",
      "step: 7000, gen_loss: 4.827947, disc_loss: 0.078372\n",
      "step: 7500, gen_loss: 3.708949, disc_loss: 0.140979\n",
      "step: 8000, gen_loss: 5.250406, disc_loss: 0.164736\n",
      "step: 8500, gen_loss: 5.491106, disc_loss: 0.110080\n",
      "step: 9000, gen_loss: 4.391072, disc_loss: 0.100240\n",
      "step: 9500, gen_loss: 5.074200, disc_loss: 0.105567\n",
      "step: 10000, gen_loss: 6.077592, disc_loss: 0.215981\n",
      "step: 10500, gen_loss: 4.468120, disc_loss: 0.099412\n",
      "step: 11000, gen_loss: 5.887744, disc_loss: 0.093534\n",
      "step: 11500, gen_loss: 5.656942, disc_loss: 0.075079\n",
      "step: 12000, gen_loss: 4.752551, disc_loss: 0.092505\n",
      "step: 12500, gen_loss: 5.682284, disc_loss: 0.077406\n",
      "step: 13000, gen_loss: 5.386811, disc_loss: 0.101259\n",
      "step: 13500, gen_loss: 4.646158, disc_loss: 0.039680\n",
      "step: 14000, gen_loss: 5.698145, disc_loss: 0.083461\n",
      "step: 14500, gen_loss: 4.513465, disc_loss: 0.077946\n",
      "step: 15000, gen_loss: 5.586041, disc_loss: 0.039668\n",
      "step: 15500, gen_loss: 6.316034, disc_loss: 0.084526\n",
      "step: 16000, gen_loss: 7.120735, disc_loss: 0.070267\n",
      "step: 16500, gen_loss: 5.511638, disc_loss: 0.053082\n",
      "step: 17000, gen_loss: 8.176781, disc_loss: 0.029212\n",
      "step: 17500, gen_loss: 6.144678, disc_loss: 0.140460\n",
      "step: 18000, gen_loss: 5.583275, disc_loss: 0.077311\n",
      "step: 18500, gen_loss: 5.840647, disc_loss: 0.042103\n",
      "step: 19000, gen_loss: 7.111396, disc_loss: 0.030435\n",
      "step: 19500, gen_loss: 4.391251, disc_loss: 0.043656\n",
      "step: 20000, gen_loss: 6.271616, disc_loss: 0.040568\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step, (batch_x, _) in enumerate(train_data.take(training_steps + 1)):\n",
    "    \n",
    "    if step == 0:\n",
    "        # Generate noise.\n",
    "        noise = np.random.normal(-1., 1., size=[batch_size, noise_dim]).astype(np.float32)\n",
    "        gen_loss = generator_loss(discriminator(generator(noise)))\n",
    "        disc_loss = discriminator_loss(discriminator(batch_x), discriminator(generator(noise)))\n",
    "        print(\"initial: gen_loss: %f, disc_loss: %f\" % (gen_loss, disc_loss))\n",
    "        continue\n",
    "    \n",
    "    # Run the optimization.\n",
    "    gen_loss, disc_loss = run_optimization(batch_x)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        print(\"step: %i, gen_loss: %f, disc_loss: %f\" % (step, gen_loss, disc_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFpCAYAAACBNaNRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXecXFX5/99HQCmi9A4SBUE6cUEQpSO9g/RepUgVgggICCJ8RVB+lAgICNKl14A0pUikd5AaWqRIFwi5vz8m7znJzW52s7szc2fzvF+vvCYzOzt77pxz7/08z3lKKoqCIAiCoH35UqsHEARBEPSNuJAHQRC0OXEhD4IgaHPiQh4EQdDmxIU8CIKgzYkLeRAEQZsTF/IgCII2p2EX8pTSGimlp1NKz6WUhjTq7wRBEEzqpEYkBKWUJgOeAVYDRgD3A1sURfFEv/+xIAiCSZxGKfKlgeeKoni+KIrPgIuA9Rv0t4IgCCZpJm/Q584JvDLW8xHA97p680wzzVTMO++8DRpK69DaSSm1eCRBELQbL774Im+99VaPLh6NupB39sfH8eGklHYFdgWYZ555GD58eIOGEgRB0H50dHT0+L2Ncq2MAOYe6/lcwGtjv6EoiqFFUXQURdEx88wzN2gYQRAEA59GKfL7gflTSoOAV4HNgS0b9Leawv/+9z8ARo0aBcBXv/rVVg4nCFpK2W3o+TH55JOP8xg0h4Z820VRjEop7QXcBEwGnF0UxeON+FtBEASTOg27bRZFcT1wfaM+v1k89dRTAGy44YYALLDAAgAMHToUgFlmmaXhY1D9PPLIIwAstthiQGyiBs3Fdfj222+z1157AfDvf/8bgIceegiA6aabDoB1110XgOOOOw5oznkyKROZnUEQBG1OQxKCJpaOjo6iKlErZfW72mqrAfDWW28BMMUUUwAw33zzAXDhhRcCWSU3AlXP0UcfDcCee+4JwFJLLdWwv9lKRo8eDdSUH8Cjjz4KwE033QTAnXfeCcAbb7wBwJe+VNMjc89d218fMqSWSLz66qsD7WG5fPLJJ0C2+NyLefXVV1s+fsey1lprAfD3v/+9/prni3M22WSTjfP8y1/+MgDPPPMMAHPNNVeTRt17PKb33nsPgIMOOgiASy+9FIBvfvObQL4G+HPnrr/2zzo6Ohg+fHiPJj8UeRAEQZszyW8tqyyefPJJAE4++WQAbr31VgD++9//AjDNNNMAsOqqqwJw0kknAbUY+Ebx8ssvA7DyyisD2SqYddZZgYGnyL/44gsA/vjHPwJw5JFHAvm4u7IeywroyiuvBHIc7kwzzdT/g+0nPKbddtsNgE8//RSAU089FaiGNbH//vsDcMcddwA11e13Pv/88wPw3e9+F8jnxxFHHAHULAqAa6+9FsjHWYXjGjFiBABrrrkmAM8//zyQI3DK683nDzzwAJCt9quuugoAkxrvv/9+pp122gaOfHxCkQdBELQ5k5wi1xd53333AXDdddcBcNFFFwFZEXlHXW+99QC44IILAPjKV77StLFuv/32QFY1Jk6pkAYaKvFDDz0UgA8++GCcn0811VTjPOqTdN/in//8JwBnn302AA8//DAA99xzTyOH3SdUfx7ToosuCmSFWwW0bF55pVZ14+ijj67vR3z961/v9HeMWnE/R7VbBSWugt5hhx0A+PDDDzt9n1bHlFNOCeTY+I8++gjIc6cl+cILLwA1q+Mvf/lLI4beJaHIgyAI2pxJRpHfeOONAPzsZz8D4PXXXwfy7rpsvvnmQPaVq/aaiXd6FaZss802QPaRDxTchzjhhBOA7Is09lif98ILLwzkSAjnzt8fPHgwkOfWfY8qc+aZZwI5ImKOOeYAaLqPdUJ4Tmy99dZAjhKaEJ43nkennHIKkPekWpn5WbYKXE9aRSuttBIAv/rVrwAYNGgQkNfbO++8A8B2220HwO233w7AZ599BtSuNVr2zbLgQ5EHQRC0OQNekRu/aiaaflf9frvvvjuQd66b6QPvCn3jKnMVw84779yj3y9bGT1RUK3E2OPPP/8cyDH5l19+OQAzzjjjBH/Pnxs18Nprtfps+i6rjFaIfletixlmmKFlYyrj+usNqtRLLrkEgCWXXBLI0S2tYKGFFgLyua51sMceewDw85//HOj6uGeffXYAzj33XAC+853vAPD+++8DtWPWGlxiiSX6ffydUe0zPAiCIOiWAavIR44cCcC2224LwJtvvgnk7LQ//elPAEw99dQtGF3nqKSNYRcVQ1cRAmWefvppINe5+MMf/gDA1772tX4ZZ39jdIDxuVoQ3R2vvnQV+OOP1+qylbMKq9jgwzE6NtWhkUlVGmtf0Io0guhf//oX0FpFrs/7mGOOAWDttdcGJn7vyWgW16mK/JNPPuHwww8HcoRMo+dzwF3IP/74YwC23LJWNfeJJ2ptQldZZRUgh7hV6QIuppxrZjv5nuQ9XQyPPfYYAOeffz6QQ7/uuuuu/htsP+JxeaOxUJnfw7333gvk5BPf7w3Kk0W3mT/XhK7iRVGh4dgMgXv22WdbNqZG4Hnm5qchet7IWuH20yW344479uj93mx1/emy+8c//gHkUhIyevToehkJN0a7cg/2F+FaCYIgaHMGlCIfPXp0Pa37/vvvB/Ld18I2VQrrKqNyVsWMbapBtja6w80YS4qq/v773//WX6sif/7znwE46qijgKx0PP5yyrRzq+tJV4oWjCFvVcQQt7Iy32WXXVo2pv7EQm+idWSa/4knnghk12eVytxqtVuG46c//SmQFbmhzH/729+AHJQgk002WV2BW/BtxRVXbOiYQ5EHQRC0OQNKkd98882cc845QPa9GZJmooWqrqzuqhCiZxEffcMmT/h4yCGHALl0bleohgz9MkHmrrvuqqdOVwk3K7WatEQ87u6wrKgp+25oL7744v06zv7AOXnuueeA7G91PVZxzD1BS/g3v/kNkK0lwyjd/5Ff/OIXQC6u5Yb33//+dyDvhzQTww4NEhAVuRafytxH8Rryne98p/49LL300o0b8Nh/uyl/JQiCIGgYA0KR6zvedttt62pu+umnB7Lv7fe//z2Q76Le+VV9Bx54YP0zoDWRDv5Nfb5l39sVV1wB5AiHcvlWfeymFnusqr0LL7yQFVZYAahWKKLJIqq48nfvcxVPOXRPi8P9D1PKq4hRGx6L689jNw2+ShhJ8+6779Zfu+WWW4CswE1J1+IwSuU///kPkC0P57IcCeI5bFiiiXytSNDzvPI885h8dA/LsXkMzukmm2zC8ssvP857G00o8iAIgjZnQChyy5a+++679buibZhsSmACUDkWVCwNazsxIyhUSs3ASIa9994byDv7qh0ff/nLXwK5vIDH6PMXX3wRGN//eskll9RV+9133w20fm/gww8/ZMEFFwTgW9/6FpD9x7PNNhuQfZc/+tGPgBwJYBlSFbk5A31JKW8UWhGW6C1/7yq3Zq637nBdufcgY6tk15ZrTSVuYpPPLcvr47Bhw4BcGE7r07l0P8hzoBkce+yxQE6rN868HC2mVeFcOXfuB6y99tpNz1MJRR4EQdDmDAhFrmIYuwXVcsstB+TGESoiC+IbHaB6Na396quvBuDXv/41kHfXm4H+fH3cKgPL12pNWBrUoj0qAfcHumqJNnr06Lrfr5WZdWMz+eST873vfQ/I5UC784sakzt06FCg5pOEXIa0Cg3Fy5jX4HorRzyoYPXDVqF4m2NVeaq6P/300/o+jueT68n3OBfXXHMNMH5W7gEHHADAxRdfDMB+++0H5ExIz9tmKnIx6mmZZZYBsvXq3Li+fG7ehnNo1FkzCUUeBEHQ5gwIRW7m39xzz82mm24KUH80ftWCOCoAC9289957ABx22GFAjgzRp37wwQcDzW0woUq2tO6uu+4KwGmnnQZk1WMUgcV7VE6OtRyHXhRFvaGzWZOtblIx5ZRT1sc/sWhFlXMDWm1ldIYZtdbBUcE6ZzvttBNQDSUuNhZ37NaymWGGGeqRQZaHVoGbE+AcfPvb3+70s93HWH/99YFcwMo1Peecc/bjkUwcriPHqPWhAi9Hk7mn4/czyyyzND3qrXorPgiCIJgoBoQiX2ONNYCab6vcQspMz66wJoKREVYItNFsK9Hfv9tuuwFw/fXXAzkDVFQ/Kihj6G1SMHZbO3fgjQow4qedMHrnr3/9K5D9zTYu7ov15PfT31EH5c/VSvJ5FWusuPei9epYX3jhhS6tHv3FPcU17fmmknUuW4Gx7JZV1mLUWlKZaxlrXfn6xx9/HIo8CIIgmDjaWpF7J1SB9eYuqD9M37l+V1VtK/2tHs8iiywC5MgH/ZO33XYbkBW3WKdbReHO/wcffFD/zozf7a+mC6pkM/n0deoj7Q/fr2M3wsEmBc6/Cr0v9NZf3x1mR7qfI66zKlbl1LrV0jOKqifnhHNV3gtwnZlpbUZ1Oa/DSKZmct999wH5PPPc0Jpy3Vmx8qKLLgLyMZr3YOOKZtLrq1RKae6U0m0ppSdTSo+nlPYZ8/oMKaVhKaVnxzxO33/DDYIgCMr0RZGPAg4oiuKBlNK0wL9SSsOA7YFbi6I4LqU0BBgCHNz3oWa8U1rlz13kQYMGjVd/pKvfNdZT36TxrioHlUKVMu30WV577bVAzl599dVXgaxqBg8eDGQlf8YZZwC1Y1a92jC2v3x5fq+XXXYZkC2bH//4xwD1Gi+9sXDKGa1GFulntoFxf0TgNMq3aUxyudaIx1DFLkayzz77AHDqqacCtfOtK8vFaKibb74ZyHNlDSNrs2gtqma12MwJMTegmRjbXsaM4qOPPhrIHatU5OK51YruY71W5EVRvF4UxQNj/v8B8CQwJ7A+cO6Yt50LbNDXQQZBEARd0y8+8pTSvMCSwH3ArEVRvA61i31Kqd9bf3gXt4Kh6vmzzz6rZ2wan6oP0hhPm8CqYh966CEg+wNVAl3dnauA8a32DNQnZ5SK9WLKu+tf+tKX6vG+fj/9hQrNCButAqMS9D/qR5wQRqHY9/C8884D8vF6XOYK+DerjFm7ZYvEKI8q1oeR1VdfHaDeUHjQoEH17OMnn3wSyPP70ksvAdni9VGL17nzfNMydA633357oLnfh9cTrwUqa61JOwY5ZiPcXKflqqU9raPfn/R5Jy+l9FXgcmDfoijen4jf2zWlNDylNNwNsiAIgmDi6ZMiTylNQe0ifkFRFIYMvJlSmn2MGp8dGNnZ7xZFMRQYCtDR0TFRxTHK3UesHzJq1Kjxdp5VQN41fTR+fKmllgKy/7VZHT36A+tcWKXO2ivWvDYyxUiJL774om6ZNKp3p6rEDD93/DfeeGMg+1m1Ir744ot6zRQ7H2ktuBeg9eSYPc61114b6F//cqN81aq0aaaZBshr2MzhKvvI9V9bY/vCCy+sK3IjOFS14vF53K4LrShVbhWida688kog77XNNNNMAGy55ZZAPn/sYOV5Jc6dlotWbzPpS9RKAs4CniyKYuzKNlcD2435/3bAVb0fXhAEQdAdqbeV4lJKPwDuAh4FvB3/nJqf/BJgHuBlYNOiKN6Z0Gd1dHQUw4cP79U4IEevbLDBBuOo87Efl1xySSBXNtP/ZcWyKiui3uLcWlt9p512qvuyVbn93SlIH6jftxX0ROWmavnoo4/qPnxVm35jraXNNtsMyHPXSMXTqKqQrkstES2jH/zgB0DuuFNltHL33Xffuu/bHAbVrNFJKm6t5mbWKppYtC7sO+q1oJzJ6WMZ9+GsY9Rd5FxP6ejoYPjw4T26MPXatVIUxd+Brv7IKr393CAIgmDi6LUi70/6qsiDCeMcL7TQQnR0dABZpTcKMzvtuqL/W/Wtr/idd96px3+b7acvtkqVAPvKm2++CcBiiy0G5LrbxlvbHarKjJ2DYYSUFq1RJu1o2Xosc8wxB5DzFsqUq2xqZRhPvtFGG/XruCZGkUetlSAIgjYnFPkkRn/VVplY9D3rS9VXX8Xa4Y3k9NNPB3J/Ua2QoPW4n6bP3M5ArlVzUNwfuOeee4Dc/ai/CUUeBEEwCRGKPAiCoIKEIg+CIJiEiAt5EARBmxMX8iAIgjYnLuRBEARtTmUu5OWiOwOBzz//vF7qcqAxevToATlnA5miKKhCcEPQ/1TmQh4EQRD0jso0Xx6IiSEWgRqINGK+bBTyyiuvALlY1kBcG62gHdPng54RZ0gQBEGbM3AlYwUIBdQzTNtfccUVgVxGYOGFFwZyoalJHQuOua7CUgkkVkIQBEGbE4o8aDlXXHEFkJW4SnPBBRds2Zhaja3ydt11Vx588EEgNwE55ZRTAFhllSj7XyVsPNGKRtqhyIMgCNqcUORBy7GUq77frbbaCmiNsmk1Nin4yU9+AtRawhn9ZPnUAw88EMhNgKvcRm0gowW50047AXDHHXcA8MADD/D1r3+9qWMJRR4EQdDmTHKK3AgJW5GpgLybfvLJJwDsvffeAKyzzjrNHmKvaVXTiL7wv//9j0cffRTIBfxPPfXUVg6pqdiU2ebLJ598MpDncoEFFqg3bLbhwRJLLNHsYfaYkSNHAnD11VcDuTG6jZs9n5ZZZhkgN6PW/+8aqPIaNlv7pptuAuCGG24AYP311wdouhqHUORBEARtzySjyJ977jkANt98cwAeeeQRgC5rodx6660AbL/99gCceeaZDR7hxKNqe+yxxwC4/fbbAdhzzz2B9ogzfuqpp+rqa6mllgJg6qmnbuWQmoJKfJtttgHyHE422WQA7LHHHkDNVz7XXHMB1Vapzz//PJDHfdtttwH5/HItavl6nFNNNRUA8803H5AjcpZeemmgmsd88cUXA7ltnzWHXL+toPpnehAEQTBBBrwi1ye+1157ATk+txyzXH6uElDlmlWnkmgFqhujGFR1qqD77rsPyErh8ccfb/YQJ5pjjz22/p3ut99+LR5N43GdOWc33ngjADPPPDMAxxxzDABbbrkl0Nr1NiHefPNNIPu8X3/9dQDeeOONcd7neVQ+Dq0uFbmNj1999dUGjbjveP4ddNBB4zyfaaaZAFhuueVaMzBCkQdBELQ9A1aRqww23XRTgHpkhMpaVTvbbLMBuZ7HAw88MM7vv/POO0BW8nPPPXfDx94V5XhhrQ3jiVUIzzzzDJD9rossskizhthj/vOf/wC1vQjnYo011mjlkJrCW2+9BcDDDz8MZGV66aWXAvC9732vNQObCM4//3z22WcfAP773/8C2ZJ1LvUbl883z59pp50WyGvUaJcDDjgAgA022AColo9ci/ftt98G8jXj2GOPBWCeeeZpzcAIRR4EQdD2DDhF/vHHHwNZiVunQrVqvOrWW28NwC9+8QsAvvKVrwBw0kknAdlX6e9VQZGX0a8677zzAlmJq4Z++tOfAnDdddcB2R9ZBdx7GD16NIsvvjgwsDMU9Y2fddZZADz55JMAzD///EB7KPEPPvgAqMWzv//++0A+LpW3yty1pjVoFIvZuu+99x5Qi5OH7HPXYrFuiXHlVeCoo44C8jEYHWZMfCvPr1DkQRAEbc6AUuSjRo3ikEMOAeChhx4CsjpVceuHPfroowGYZpppgOxvNkbU31PBV7km9lVXXQXA8ssvD+SsVSMJVDdVUORaTKeddhpQ84EeeeSRrRxSU1CBmrmpz9gM4iqj6j744IOBmnVaju5aaKGFgJyVq5Jecsklx3mfmP1oRqsRH59++imQo3n0lVcB9888lsMOOwzIVvsuu+zSmoHRD4o8pTRZSunBlNK1Y54PSindl1J6NqV0cUpp0qt8FARB0ET6Q5HvAzwJfG3M898AvyuK4qKU0unATsBp/fB3uuUvf/kL5513HpBVhHd6fd7f/e53gay4Vave+d1FF++2Va7Ep59xxx13BLLq04+pb7MVNSDKGAX08ssvAzUratlll+2Xz3bOfSxn7WqVtQIzFq1gaOyxc2McdRX7vGrdnn/++UCtHlE57n277bYDJj6bWItYPB+NMquCIvdaoTXpGN0XmGWWWVozsLHokyJPKc0FrA2cOeZ5AlYGLhvzlnOB1s9EEATBAKavt/+TgIOAacc8nxH4b1EUo8Y8HwHM2ce/0S1mOB5zzDF1X/cWW2wB5BopZaXg3dR4XqMoRD/YN77xjU5/v0o4Vn2YRt4Y46v6qwIqcf33s8wyS6+tHVWsmay//e1vgRwBIXPMMQeQVV4z9wpcm1pJrk/3Xqz5Y0SEas/vae+99+43i6W3/PrXvwayIk0p1X3iq622GpDnwgzOnmakWiXRz5ZWH/PYeK3Q0lOhO5f77rsvkKsftoJeX51SSusAI4ui+NfYL3fy1qKL3981pTQ8pTTc5JAgCIJg4umLIl8OWC+ltBYwJTUf+UnAdCmlyceo8rmA1zr75aIohgJDATo6Ojq92PeUoUOHAvDSSy/VY5HtOtOVkjY764gjjgDyXVdUTCr6KmWYdYXHrG9YVdRK33AZMxidl913332iP0MltNtuuwHw97//fZyfGzGhv9mIEZW6cffNwKw/x+D6fOGFF8Z5VImXufHGG/nTn/4ENF/xqUCfffbZcZ5PPvnkzDjjjEDel3niiSeAbIFo9TgXJ5xwAgAbbbQRkOfw7LPPBsaPLqtSv1bPI/cFzCnxmuDc+thW9ciLojikKIq5iqKYF9gc+FtRFFsBtwGbjHnbdsBVfR5lEARB0CWN2CI/GLgopfQr4EHgrAb8jXGw1vg000xT9xOXd8NFX97Pf/5zIGecqci9y9qNxazDduDKK68c57nfQZWsCaM2VGArrbRSj39XZWitaudM1WtFQV83rt7s3nvuuQdojiJ3nf35z38G8hz4usw+++xA9kPrx7/mmmuAWocdI0K0KJplYTlmI70cW1EU9bojjkmLwt8xGkcVbzVHrYq77roLyFFMvk81675GFdB6tDenMe6LLrookCPa7GGw4YYbNv2c65cLeVEUtwO3j/n/88DS/fG5QRAEQfdUL2h1IvAu/tRTTwE1X5aK78UXXwRyxMYrr7wC5GgWa1145/SuazW6zTbbrNHD73fs0qJPz25IVWLnnXcG8lh7Un9adWd2rfN+4oknAlmJi3PpPocVLidG/fcVFbUb+eWoDmv96CMW16d1chZaaKH68bumzRtoFmYsGkc+atSoetSRx+V5pLVg7RiP17FbD0h/cvn3Z5111nGeVwn30w4//HAg70UdeOCBAPzud78Daoq82VQ3pi4IgiDoEQNCkU833XRA7e5vDQ9ji1Xo5Sw/d9W98/tZhx56KAAzzDBDI4fer3hsPpZ306uE/lZV8rHHHssPfvADIEcFlON1b775ZiBHfKhWy0pc/H1Vv/0gXSfNQNVWjkYZPHgw0H0PWJXt5JNPXp9PM3WbjTHjRqB89NFH43XUsq+ovm+fi2tTC2WVVVYBskL3GL/97W8Dee6r2CHJsXptMZtcn3krrIlQ5EEQBG1OWyty1cBPfvIToOb3trOPkQsqAe/wxr+q/l566aVxPnOttdYCqqkEusJolbLV0VVscispd4lfY4016pFBc85ZSwJed911AepdaIxs0OetIi/jnBsBom+5XM+kGbgOVa6iT7yr/AbXqf7/Dz74oK7OF1544YaMtTuMfrr88suBWgSKWcNf/epXAbj77ruBHIVTRmvKn6+wwgpALSpnbIxM+uSTT8b5/Crxhz/8AYAhQ4YAeS6tQtoKQpEHQRC0OW2tyEV/20orrVTvhvOtb30LyH6re++9F8gxn/pPrfGg2mtm1l9fUe2Z2aiaUyGo6qqIXVU22GCDupL5179q1R7MC7BD+5133glkdWaMv5EfWiTGbKtg9dP6/maqu7JF55x85zvfmeDvqUjNgIWc5diqDF3Hblz+EksswR133AHkjlldKfEy+o/1t/vZfl/GkZety1aghafV4P6bNdc9//74xz8Crd1XGxAXchfDSSedVD9RTN/2wu2X7oaRFxITGkxA6CqRqIpYZsDNQI/Vm1hPT65W4JydccYZ9Q0yXSCmeRsuaDq3rhEv9J5QfpaPFnLaf//9x/mcZuBYyxeiQYMGAdndVb4o6+Iz5d3wvtlmm60e1tZqd58lD8YucmaZ6LKI6ArPQ5uflMN/vRhWocXb6quvDmS3UbmNnUJim222acHoxiVcK0EQBG3OgFDk8uUvf7mezlxu5FtOWCgrppVXXnmc91UZVc31118PjJ/2vvbaa7dmYL1gqqmmqheOshG2LqHuwu3KZrob1TY7sLFxM/nHP/4BZOtB9arLzoa9jt2yAWM32oCs+jbbbLN6yGarcX19+OGHdXWu28e50jXS1Xmku8LNTN/no1ZkK60P281ZYrh8LdFdayGwKpS4bv0IgiAIgj4xoBQ5ZH+xjVJVeSqdM844A8g+SH3i+rvaCUPcDM9TxRx00EEtG1NfcFPSJgvDhg0DcsElrSj3ANxkUhVWIVRNZaqVUE5RHz58ODB+I4Vpp631ZrGs73rrrQfAUkstVZkyxB7LnnvuWW8abQlpx+/+RDkhSNwwvPbaa4E8p56HtnZrZWtFrQ3DYg2U8JhuuukmoBrNzCUUeRAEQZsz4BT5kUceCeSQIYsX6Vc24kFfndEqSyyxRFPH2RfKvmGPzYQRk57aFX2ORg0YndMOWKZ1nnnmAeCcc84Bcgil686EKIuzmQZf9sdWkR/96Ed11WqK/WGHHQZk//JWW20FZKVtMwa/h/JxHnLIIQCsuuqqjRx6j3D92XRaf77RTxbWqxKhyIMgCNqcVE4hbgUdHR2FvsO+Yly4sZ3GgBq/W26DZhSBDYvbIWpFbFy77bbbAlntWO41CBpBURT1MgnnnnsukJW3e1Eq9rELbUH2K+sDN6HIvS1/rwq4N6EVVS5L0Gg6OjoYPnx4jy5IociDIAjanOrc/voJC9PrGzet2Oaw3l2981exHVpPMbLB0qDt4F8N2p+UUj3b1LK8FgMzWky/8ti/Azm6xUgkfeNVUuLiMVQhTrw7qj/CIAiCYIIMOB95d3iXHTlyJJAVfBVqOwRBu6OP3OJfRhzNMsssQM4BaHXdmHYgfORBEASTENVzTDUYd82/8Y1vtHgkQTDw0NfdXbneoH8JRR4EQdDmTHKKPAjbxgsHAAAgAElEQVQmVdwPs2a6+0LtGLEVjEso8iAIgjanMoq8KIoBpwxUQAPtuCBnyraySl0wcbgO+1q174svvqhnSDv/rYy17ml3ooHMpHvkQRAEA4TKKPKBqFoH4jFJKPFJl48++qheG8Xet13VH28Gk7ISl/gGgiAI2pzKKPIgCNqDIUOG1Dtt/ehHPwLghhtuaOWQJnn6pMhTStOllC5LKT2VUnoypbRsSmmGlNKwlNKzYx6n76/BBkEQBOPTV0V+MnBjURSbpJS+DEwN/By4tSiK41JKQ4AhwMF9/DvBJMBZZ50FUK91bd0OfaDuOZg1+Oc//xnI3XWCxmKdonPPPbceKXLKKae0ckjBGHqtyFNKXwOWB84CKIris6Io/gusD5w75m3nAhv0dZBBEARB1/RFkX8T+A/wp5TS4sC/gH2AWYuieB2gKIrXU0qz9H2YwUDGPo8HH1wz3FR+XVXmfPDBBwH47ne/C8Cll14KwNprrw0M7GihVvLyyy8Dte/361//OpCrGQatpS8+8smBwcBpRVEsCXxEzY3SI1JKu6aUhqeUhtsYIQiCIJh4+qLIRwAjiqK4b8zzy6hdyN9MKc0+Ro3PDozs7JeLohgKDIVaPfI+jKNH6G+99957ATjuuOMAuP322wHqCuOYY44BYLvttgPaW92VFW0Vj+Wzzz7jqaeeAnLGoT7xcmasNaydS/20e+21FwDzzTcfAAsuuGAzhg7kjlOO6dVXXwXgueeeA+C9994Dctz9UUcdBcCIESOA7O//3ve+B8Cjjz4KwOOPPw7A97//fc455xwg95BsFfrDU0r1/YmBxFtvvQXAVVddBeQa6t/+9reBXNnx3//+N5D3ZuaYYw6gtfHsvf7LRVG8AbySUlpgzEurAE8AVwPbjXltO+CqPo0wCIIgmCB96hCUUloCOBP4MvA8sAO1m8MlwDzAy8CmRVG8M6HPaUaHIO+222+/PZC7dlszQlR98847LwCzzz47ABtsUNuzXWeddYCs/qrQ6eT9998Hcv9Eu33bj3TFFVcE4IADDuCb3/wmAB988AGQeyhOPfXUQPNVxRVXXFFXd++++y4AH3/8MQBrrLEGkL/r1157DchWk53ZHfs999wDwCKLLNLwcXveOOb99tsPgNtuuw3InXG0GlwnHlv5vPPn5d6Vo0aNqq/BF154odP3NJrnn38egAUWqGm2L3/5y/U1V4X131ucm/PPPx+A448/HoA33ngDyNcGlfmbb74J5N64/r4/v+WWWwCYe+65+2V8E9MhqE8roiiKh4COTn60Sl8+NwiCIOg5Az6zU+Wwxx57APDwww8D2bdZxtf1g6mCVF6qva997WsAzDbbbEBz/M8PPfQQAEOHDgVgvfXWA2CLLbYAcp1plYTHfuGFFwJw7bXX1iNC9OmqqFTqRx99NAAbbbRRA48kf8977713XZ1ecMEFQI5GsV62yueVV14B4LDDDhvndd83zzzzNHTMY+OYP/zwQwCefvppIK8TcX1Yi0Tf+Ouvvw7kTlW77747AOuvvz6QrY/NNtusPmdakWuttVZ/H06nGE20yio1Xeb3/dWvfrWtlbg4hw888ACQLTzXpr7vNddcE8jn3wwzzADkOVfBuy7PPPPMpltNUWslCIKgzRlwilzV8Ne//hWAP/7xj0COPValliMiutor8HXvvieffDJQ8zdD9jF/9atf7cejqKGy3nDDDQG48cYbxxmT0Qw+N/LGWuEzzjgjACNH1gKH3nvvvfr3Iz636/mWW24JwPXXXw/Ayiuv3J+HVEclO9VUU7HjjjsCsOyyywJdR2eonLQmRPXz4osvArDYYov1+3jLuJeg/9qIm+mmmw6o+TcBfv3rXwPZ4lHtGcWisnUOnXOV/ejRo+t+9csuuwxoniLfYYcdgGwdyAorrNCUv99o/O5/97vfAXDCCSeM83p5v8h1ZySSewc//vGPgZrFC7W6M+uuu24jhz4eociDIAjanAGnyPUjDhlSy01yp1n/saj6vPuqqFVCZdWnctV37ucaMdGfPPnkk0DNfwxwxx13AFnNOebyMc0666zjvN+oFdXeCy+8UFfpqtc777wTyN+Xav5vf/sb0DhFrvXw9NNP17/brvyKjv83v/nNOM9FX+55550HwP/93//1/4C7wAiGW2+9FchzpJor+5K7svxcVyuttBIwrgr2M1R+jcYxLrnkkgBcffXVQD4H9Bn3B1q6+p2nn75WY8+10IzuP1rlzmVXOCbPIcd8zTXXADXfOOT12EwG1IX8xRdfZN999wXGTSeGvCFmKJuJGZrzYiiSm6LeGNzQ8AT75z//CWRXRH9gwsXhhx8O5Iuq5vrmm28O5Au8myuOadiwYUA+1jKGjwHMNNNMQHYB6Iq6++67gXyhbzRf+tKXuj1JyzfRcsKQJ1izXA6d4Zi6Ohbn0s1zwz8VFIa+ld0Yk002WT28zU3HZqGo8Zgc69133113u/QWN3lNoNLV5Lp0bk2Yuummm4BqJbU5Fje03ZT2fG0m4VoJgiBocwaEIvdOuNVWW9WVpK4SVewRRxwBZPdDGRWAoXz+nu4JzSbdGf1ZLMjxO0Y3tzyGP/zhD0AtFA2yErj44ouB/jE/NaPvu69WcUEVWAW0fvyeyserm+b73/9+C0bXMzbeeGMgK27LEngs5cQ0E9K23XZbttpqK6B707+/0cL5f//v/43z91966aVef6bnlUlrrmVdUm7M+9xEPi2aVpcpGBvdqwYd6I6ceuqpWW655YC+N7ruKaHIgyAI2py2VuRuSO60005AbZNQFevGlxsz3fnWVEaqDjcBDflSEeiPVcH2BxbwKoem+eimimP0WH71q18BcOyxxwKw+uqrAzn5afnllwd6pgrcC/Bv2FS3CpjCX05ici423XRToOu9gSrw+9//HoDTTjsNgCeeeALI60qL0HBWrbDVVlut6Urc9bXooosC+Xs2dLc3obZXXHEFkNeZ1pRrvPw9lH+uxdKZIi+HEvc3WoJafO6XGeigleU4Tj/99PqadRN88cUXb8jYJBR5EARBm9OWity784EHHgjAlVdeCdTuyEahGMbV1V3aokaqPN9nGq4RIfrsvNv6fu+0P/jBD3p9HH6W4XKqkrIKsfWZSsiImnKIpGFiPqpqysc4Nu+8U6tnVo4IMf2/lbhXYCRR2TfuPsUvf/nL5g9uIhk0aBCQo6kMUSsrUK0y53DZZZeth+Q1G/eHXJcyMXsRjzzyCJD3d7SmdtllFyBbk34P7odss802QFbDnhOd0Vslrp/eksOW39AC8hqgxewYHYtz6Nx5vqaU6klDhu+q4htlXYUiD4IgaHPaUpEbg/uXv/wFyIpz5plnrrcLK9/5vJsat6rPSpVXjgX1sSuM7uiLf27bbbcd5285Zh/1+apitCJUACp048MtzHTdddcBubCXO/8zzzzzeGP4xz/+Mc5x+NjK6ADnc5999gFyMSPxuEx8mpBaqwoe0/333w903TyjXEDs/fffr+cXuFfSLMpWqOeK59+E0NJbaqmlgGxpGAljqYvyeWP6v6UPtAYaUaRrtdVWA3LpB/eS/NvG0RsVpbX/85//HMjF3VTmnp/nnntufc787rR4G9X0JBR5EARBm9OWilzcRfdu/95779VVmndJs6y8Q5ohVo5jVYGa+fnYY491+jdVy76vLzgGFaWKwBhiX7fBgoracq3uA6jMVUwqWH2cnamZsvLzue9tdAadY/3www/r2Y6WcnUMFjorZxbeddddQPMVal9wH8TY43JWoN+H/WvHLv6mYrT5SiMKtHVGuXSC6tI2dJ3huWgDF/3GnjfmPnS1vizWpgrWx9yI9eg1oRzdZS7JzjvvDOTcE8/H8ljKBdOOOuqoesllo97cewtFHgRBEHRKWypyd/HLha7+97//1X1vFlgqN5BQXXh3tdaI71clu2vu3VdVuPTSSwO5AUBf+O1vfwvkCBFLnZopphLoacamSlYfck9YeOGFx3leLnPbX6j4tXROPfVUoKbAbLKg4vN4VTqqOedik002AbJ1Zd2OKqIyM37czGCPzYgJ16UNPYyK+vTTT+v+VeubXHrppc0Yen1M5ezL22+/fTylLc6hhd/KeK66tv1s14UqWGtSBdsIRW7D60YUudp1110BuPzyy4HO96f6k1DkQRAEbU5bKnLvzvoMf/jDHwI1pW41QpWQ/jzv8EaKGP+tX0slbnF5Gx+oDq3KZtakO9h9UQr6wo0xthxmM6IwHHe59kyjfONGzujzVJl+9tlndaWnatcqMGKhHDVh6VM/6/TTTwdg1VVXbegxTAyO9eyzzwZyHLHrySqT5WxU48f3339/oObHLUe8NAstPC0BLcVPP/20XoFTf7KZzlrJ+v61OFTwxv6bFelaLzerdk00UpE3knKklVUcG0Uo8iAIgjanLRW5lLPlUkpd3rlVd2YLqhDOOOMMIFc3tHqin2MVQCsTWty/P+Ja9ZM2o3h+V5RVXqN8eVb70/LxmEePHj3enJUjaLpqlO1cGdWj1aVCd66a3QgX4JZbbgFyqzfXm/5865h0xdprrw3UslpVq1o1ja4tUuaYY44BsrXw2muvcckllwC5Do7x4bZNK68rx+p5WG6KomUy55xzArDXXnsBOduynSiKol4HyeuHsemNIhR5EARBm9PWilwmpGRVL1YoswqdisFaECoFfXfuaKvEjW5pRIaZKvVHP/oRkCvENVJJulNv3K6KyfoS/U25znRnLc+MgFhooYUA6t2e9C8a2WD2rhEQUq5N4/tUd77eyBrR+rO32247IB+vWYC33XZbjz7HdmLf+MY36vs1+ou1ZhqxFjtDv7fnzlZbbVXPRvY7d82WMznLlSrLXZ2MF1f127S4SvXwJ5atttqqvjdnhFGjradQ5EEQBG3OgFDkqukzzzyzrlr0uRlXbn1xs0HNElTdqDrcVd9xxx0BGDx4MNBY9WP9F60D1duJJ54I9L1X49g1M/SzqlZVex6//ub+RuVWbqr7la98pa7Ajbk1c7WMVpJzo5/WmGv7jlp5TkvH71GV19d+kxPCLjGuM6OdrGnTVUSSczRixAggV/Z84okn6hZnK3z9Y7POOusANb+49XycM4/XaI1y7Xxxbg866CAgR5FVqfPPxKIVZheoW265pV4h0qzRRhOKPAiCoM1pa0XuXd9IgHfffbd+ZzeCQXWmz051o1LQF+kddMMNNwSy+mhkdxZVmN14jHQwBv7www8H8nF6dy+rurHrIEM+VqN5jEl+++236+99/vnngRyl4mfPPffc/XR042IPQ+PWrdi455571jNbe2r1eJzWuPbRudMKM97ceP0llliiT8cwIfzOVZh+z/7tro7NKoH77bcfkHMJrDD4pS99qd41yBrezfKNl/F7X3/99euZzfq2raHi+rF+jhaeceX6xKsUF65V6jWjp2Nzjp3zYcOGAbXvoNwToNGEIg+CIGhzUmfRA82mo6OjMEtzYtAHqrpT3UC+q5Z7caoMjEHfeuutx3lsRW1rFbjK1Noaqld9w/oXVXn+3j333APkyBqV+KOPPgrk+OOZZpqp7rM1E09fucq8UQpC9eI+wGKLLQY01uJx7o3DbmS9C4/P9eV55R6L0U9zzDEHkKM8TjrpJCDPmZ9jvZwVV1yxbpn5nbUi32AgYhVN6+CYGaw1bta30VHOkfkLWh3ui8j5559fP8/6QkdHB8OHD++RedCnFZFS2i+l9HhK6bGU0oUppSlTSoNSSvellJ5NKV2cUqp+1f8gCII2pteKPKU0J/B3YKGiKD5JKV0CXA+sBfy1KIqLUkqnAw8XRXHahD6rt4rc7DCzyh566KG6CjPO1Z1+M+mMdFAZtToSALJ6K2eVWp/DMRqbqgL35/qCjW5RDRiBY72LjTfeuK7qVRtB/+AcutdQzk8ox37rU9dn7HMja37yk58AtQidZtUfn1RwLqwRbscf9yVU3maBO7f60j13Vl99dQCOPPJIIO/V9dceRtMUObXN0qlSSpMDUwOvAysDl435+bnABn38G0EQBMEE6JOPPKW0D3AM8AlwM7APcG9RFPON+fncwA1FUUywYEJvFblj11f+zjvv1LvGmLloVEq5tnI74vEaiWM3JF9Xgetb99hbFeUwKfLSSy8BOQrFTM5yn0vXob5wMyJ/8YtfANm3bqZx0DiMA3ePTZ+31xX3PYyI02oy47hRc9QURZ5Smh5YHxgEzAFMA6zZyVs7vVOklHZNKQ1PKQ23vVUQBEEw8fTFR74psEZRFDuNeb4tsCywKTBbURSjUkrLAr8simL1CX1WbxV5EATBQKVZPvKXgWVSSlOnmp24CvAEcBuwyZj3bAdc1Ye/EQRBEHRDry/kRVHcR21T8wHg0TGfNRQ4GNg/pfQcMCNwVj+MMwiCIOiCPsXeFUVxBHBE6eXngaX78rlBEARBz2l9EHUQVIje1t0IglZSiQt5URSMGjWqEsk5Qc9oZXu6RhLJN+2HZQ0aWe6h6gysszAIgmASpBISOKUUarzNGGhKPGhfJmUlLnE2BkEQtDkhg7vBYkZuglnkqJ3wGD7//PN6C7ygNbi3YAmJRjaCDiYdQpEHQRC0OaHIS1iy4MwzzwRy8SObOTz22GMtGdfEoAK3YP4BBxwAwOyzz879998PNLbJQpDnYOjQoeM8WorYn+vfdT5cX+1o+Y2Nx2c5aQtQWarZUrA23o49l74R314QBEGbE4p8DPou//CHPwBw2GGHAbl5hQkiVWbEiBEAbLHFFkAunD/XXHMBcMUVV/RLC6q+oMVjs4snn3ySK6+8EoBrr70WgI8++gjI5XcXX3xxAKaffnoA9t57bwBWW221Jo164rE0qk0HLJGqUjXRyMYTzp3zYzlcG6BUAfeJPv300/o8Wuzu//7v/4Dc/uzNN98E8vnj+1XelljedNNNATjhhBMAYg+nl4QiD4IgaHMmeUVuO6ddd90VgBtvvBHISsJmzPrKq4RqbqWVVgKyAlf17LbbbgAcddRRQDWaFGy00UYAXHXV+EUxyw2zxdZ2+pOfffZZAIYNGwZki6NKOAc2zn744YeBbOltu+22QFa5a6655jjvO+uss8Z5fxXw3Nh+++3rUTeipdFVWexyqQOtrssvvxyAPfbYA8jNGoKJIxR5EARBm9OnVm/9RTMbS7h7fvPNNwNw4YUXAnDXXXcB49dt2HDDDQH43e9+B1SjFocqbuuttwZyyzfbhtmqytZvVcAuULPPPjuQFRx0X5jKn6tytSz0kV988cVANVva3XTTTUCO3thggwm3sB00aBCQfeq29asCWqkzzjhj3RrUYvW582qmthaJDY4936644gogn2//7//9PwB22mmnxh5EL/CYbrjhBgCeeuopIFsT7vfYCm6uueaqr0nbwun7n5gibM1svhwEQRC0mAHvI/duusMOOwBw6aWXAtkPazSKu+i77LILAD/+8Y+BHD9eBbSeVAb6U7UejByokhIX49c7o6y4xefOoXOm+nvwwQeB7G/VIqkSK664IpDVWndoTc0333wAvP322/W12WpUlY888khdhWod6fM3WsfolXINpaWXrrUquOaaa4A8l1Wsl6K1YEPs008/Hchj9rG8p/PGG2/UI628frz11lsALLnkkgBMO+20APzmN78BYO655+7TWEORB0EQtDkDVpHrR15mmWWA7NdS1arE999/f6C2Ew/VjIAQ/cxmbI4cORLIfshNNtmk81+sAPqzVSjGSU8xxRR1dVL2H/q6Mdb6aI2YeP311wF4+eWXAVhkkUUaNfxeow+5pxx00EFAXqc9VfLN5Fvf+tZ4Vt+///1voPsMzddeew3IVpTHWYWIKtEC1F9vfoPWhhbS8ssvD9QsFMjr8u23366v1eeffx7I0XFa035PPv75z38Get/IJBR5EARBmzPgFLmxxXvttReQfXUqo9133x2AQw89FIAZZpgBqHZLL31wxotrXXg3Nya7ysdQjgGXCY3Z47777rsBWGeddQD44IMPgOzD1Fe+4IILAuP7ZVuJirO7uTn++OMBuOWWWwAYPHgwUI0oqZ7QnRJ3roy0cm5Vt+uuu24DRzdx7LzzzgBcdtllQD62H/zgB0BW6GW/vor95ptvrmcfq8T9DK9D66+/PgCnnnoq0PdzNxR5EARBm1Md6dIPjBo1qh6nqv9U39u+++4LwC9/+cuWjK0veLcu1+n44Q9/CGRfcjswMcpDFbPccssBORpHBa7a/ec//wnkGjNVwLGZbWvdcav/LbDAAgAcffTRQI43X2KJJQC44IILmjbWRvL+++8D8NOf/hTIFpkx/1rIVdgLePfddwG4+uqrgWzZPfDAA0COJOoK1/bnn39ezxT33NSa/uY3vwn0//GGIg+CIGhzBpQih1znuBzjaRRLO2IlObP9VDMHHnhgy8bUTFQ6W221FZDj533d6J0q7REY0+9ejP5TFZrrslyjxEiIKmapTgzW+THr+NVXXwWylaVP3O+nCpx00klAnpvDDz8c6F6Je36atbvAAgvUq6g2y1oORR4EQdDmDLhaK/rG9UGqxPVNPfPMM0B7dSTRJ+yuufGqVor717/+BYyv4srHWCXF2husXf3Xv/4VyMejD/32228f5/VWMv/88wPZJ67ydk66Ou/MnrQO+bHHHlvPD6jCcXWHEUb6hLVEjPCwyuN5550HVGN/RwW+6KKLArU4cIAzzjgDyNaDc2fUlHX03X8zAu7pp5/ul+tL1FoJgiCYhBhwPnKr66233noAXHTRRUDODtx8882BHL1iz8AqYz9H+zjqE15jjTWA3NVIn56xq6JSn2KKKepxu9Y+8fuqMqq8O++8c5zXy77zKihWrSMzV1V75Xjycscc0doyU3LzzTcfz5qswnGW0aJeeeWVgRw37lhddyr1KnXcGjsjE/KYzz//fAD+9Kc/Adm6UnlrNVlL3ZosrbD2Q5EHQRC0OQNOkYv1w//xj38AWZHrX7XbiRXNNttsM6Ca0QJG4OhPVM3MOeecAFx33XVAVuxmBVo3Rh/7s88+W99D0B+oyqhiBqGqVR+xcb7laolmfFYBI2qME1aRm8/gnFkXf6211gKyUrUGidm6N9xwQ13d+zv2Lm0lxoPb8emNN94AshI3bv6UU04BYOONNwZyZmOV9qiMF9dqsHaPGZwek9cGFfkKK6wA5JosrYyF7/bbTCmdnVIamVJ6bKzXZkgpDUspPTvmcfoxr6eU0u9TSs+llB5JKQ1u5OCDIAiCninyc4BTgPPGem0IcGtRFMellIaMeX4wsCYw/5h/3wNOG/PYdFSYHR0dQFbkKgGVjxln/vxnP/sZUC0/pD5vfXizzTYbkLP/VATWmSljJbaTTz65rpy0TJZddlkg+zirkGEnzonx86pb50bLxO+jClj3XrWmr3uVVVYB8jGorq2hXv7e7Uw1ePDgesXARx99FMix5s3GLM3FF1+8Xl/bubCetlUuzz33XKCadcbLqMi1/C655BIgRxCJFqGWrntXVaiD360iL4riTuCd0svrA+eO+f+5wAZjvX5eUeNeYLqUUvV304IgCNqY3vrIZy2K4nWAoiheTynNMub1OYFXxnrfiDGvvd77IfYOO5gY6WAdbP2pZ555JpDVnj0FjXv1eRXQutBHbkVHaxt3p9BUFgcffHD9NbPR9HWq+qukyK277picG1Wtz6vkb1WhWhemXLdbP6tqriv0JU811VT1vQLXdLMVuX1D7e7zyiuv1I/TyClVrL7xiaXcZcfPb4Zl7N848sgjx3kUcwD0mQ8ZMgTIfUa1RlpZwbG/z4DOvvVOMx9SSrumlIanlIbbMCEIgiCYeHqryN9MKc0+Ro3PDowc8/oIYOzmc3MBr3X2AUVRDAWGQi2zs5fjGI8nnngCyNl+RnwYnaFiOOqoo4Cs1PVZnnjiiUC1FLlx1B6DGE/eG/RxqsSNpa0CQ4cOHefR7NxyNqSqtac1vxuBYzPbT399X8ei+h45cmT9+GaaaaY+febEosXz/e9/H8iWIOTv3P2Xsj+5pzz99NNAzoHwuWvbdaof2n2T3v693qAV5TXFfSbPHa3+dlTkVwPbjfn/dsBVY72+7ZjolWWA93TBBEEQBI2hW0WeUroQWBGYKaU0AjgCOA64JKW0E/AysOmYt18PrAU8B3wM7NCAMU8QFbVKyZjP8h1cf7P1y+3YoT/QHeoqxOx2pbyN4Z0YVI5GqViTZtZZZ+3l6PqO6s4IGmOxu+pSLioi328t72aiYrTujdEp1uHoabcivwPdjHalf/vtt+uRH83KQvbcmWeeeYBsrRolNMsss/DKK7WtMLtVudeictZa8nw6+eSTgfw9XXPNNUDOgFX1+redW+de5d/KPRy/B8doboBdj1pJt6usKIquqvWv0sl7C2DPvg6qtxRFUS/k74nRnfntyeH7XDgmBVThQl5u4Osx6A7pboPJk+zhhx/m4osvBvJFzxtZq8ItR48eXXdjeUH2uMquFMfoSW+ihqF+nuReNEzyauRmqBvRjuX6668H8kluc+999tlnnGPwAq9gsOmyIYa60SaffPK6a2PQoEENOw7I3/c222wD5AuXY7XJ9xdffFG/sHrcFjR78sknx/ksH/2enNvyXJoo5d+ydIS/50ZjK8OCvUk7Zst9mFzXSqqz3R8EQRD0igGVop9SYpZZapGQ3jVNYjBBQReKJqxJNJqv/l4VgvzFRAWL97gRtsgiiwBw3HHHAbDMMssAWQVtt11tG+Pvf/87UEvhtxmFrah0PTUb3SbHH398vbCZr3WlxMWfGxbmHIumrirX50cccQTQvxtlWmw2fnazTs466ywgN9l1nalM3VBU2YrHPHjw4PrabXT5CL/Pe++9d5y/Z+kH3SCffvppXTl7PCrorspGe3wedzm5y4YwFt2yZIGPrWyobXlkQ3ZN5bfBexXCX1s/ggrVI5wAACAASURBVCAIgqBPDLjGEqqGJZdcEsibLeXj9C6q8tYXp1K1JGWVKPthVZqffPIJkNWNilM1Y6GsxRdfvF7EqJnhW51h6d1DDjlkPHVaLorlHoAqTwXuJnC5bK/4+6o590NsP9YfVpfryuQQ/fP6vm0wUW4YLapeFaqb8Pqcjz/++KYXNNNqvfnmm4HxS+6OvW/k2Gx8rb/4kUceAfIcuTlquO/aa68N5M1PQyvdUK1CiQznxAQgzx39+Rbk0wvQ30RjiSAIgkmIAeUjB/jGN74B5MQBi/jYSEFV693WSIff//73QG5IUUX0R6qYVKZaHUbsLLbYYkBWTlVQN2UsL/DJJ5+MF16otWBopJE2prurDD0u/bJG5xxwwAFAbvKg791IC9Vyfyhyx2BzARX4P//5TyCXgFCR+reNALGMsg1+q+BvvfTSS4Gcfu/3qJred99968Xo3BvQ6vH7sGxtlXFdlC0316Mhkhan81rh3lOzE7QmROtXTRAEQdAnBpyPvDvKx9tVy62gsRh5M3jw4LqP2zhpCzDp0+5tEki54XErLJNWlg/oL7qLImo3jEm35LA5FYcddhiQ/f5GiRn1ZW6Av9/oHJPwkQdBEExCDDgfeXeU1US7q4t2RZ9wOQa8P6lC276BsL4GwjGMzcILLwzk5jK33norkKOZ9H0vtdRSQPaJ77777kDrI746IxR5EARBmzPJKfIgCCZt3Isx2skaKg888ACQY+GNZDMSrsqEIg+CIGhzQpEHQTBJYjTTbbfd1uKR9J1Q5EEQBG1OXMiDYBKhKIrxYsKDgUFcyIMgCNqcylzIQyk0nv78jkePHt1lC7Z2ZiCr1s8++6xeX2QgMZDnrKdU5kIeBEEQ9I7KRK0MtOyxKtKf3/FArU0zkNdhKxsXN5KBPGc9ZWCejUEQBJMQcSEPgiDoAaNGjap3sWoUvd17igt5EARBm1MZH3kQBJMOqk5r0Te7L2lnWL/e7mK33HILAOeffz4Azz//PAC/+c1vANh88837fQy93XsKRR4EQdDmhCIPgqBhGN9t3fkVV1wRgEceeWSc96211lpA7pPZTOx5u8wyywC5e1XZV+2xHHLIIUDuBzzjjDM2ZZwTIhR5EARBmzPJKHLvpt5lP//8cyD76GaYYYbWDKwBeGzXXXcdkP1ua621Vr1TeDviHNqZ3rjoL3/5y+M8tiMe2//+9z8AXnvtNaBWO7udYvb1M1988cUAHHvssUD2O3u+lTMx//Of/zRriONhx59XX30VGF+Jl3nrrbcA2HvvvQE499xzAZhiiikaNcRuaZ8VEgRBEHRK+8qzbvjkk08AOPTQQ4HcEfuDDz4Axu+wbl++3/72t0DjO2T3BdWMyvvss88Gsu9On19Z9Uw55ZT1Lijf+c53mjLWnmBs7uuvvw7A448/DuS5e+yxx8Z5n8dlT85ZZpkFgMsuuwyAZZddthnD7hMew5NPPgnk7jQXXXQRkDu2b7vttnW/skpx2mmnBaqV0ejYfvWrXwFw8sknA7kvpj8vq92pppoKgOOOO64p4+wMLTt7ef7rX/8C8lidK61Z33/77bcD8Otf/xrI518rlHm3ijyldHZKaWRK6bGxXjshpfRUSumRlNIVKaXpxvrZISml51JKT6eUVm/UwIMgCIIaqbuqYSml5YEPgfOKolhkzGs/Av5WFMWolNJvAIqiODiltBBwIbA0MAdwC/Dtoii+mNDf6OjoKIYPH97ng4F8Fz3wwAMBOPPMM4GsDFQxvk+/6pxzzgnAt771LSDvnlepPoWV64YMGQLA9ddfD8Arr7wC5GPTz+rzaaaZBqgpBfsRXnjhhQDMOuuszRh6l3zxxRe88MILQFanP/3pT4F8XFpPZVTks88+O5DjfX/4wx8C1awH47FsuummANx///1A7h/puvR9n332WX0NqtI9Lo9Ti6wVsdiO969//SsAu+66K5CjVPy5a9Hrjc/tVH/XXXcBrfUz33fffQCstNJKQLZ4HavnyuDBgwHwmuW1ZdVVVwWyZdhXOjo6GD58eI/Mrm5XelEUdwLvlF67uSgKc1XvBeYa8//1gYuKovi0KIoXgOeoXdSDIAiCBtEfPvIdgYvH/H9Oahd2GTHmtaYwatQobrzxRgD++Mc/AlmdujNtdIqdsY0ZddfcaAF3pM844wygGv7I/fffH8gKTEXqsemr22CDDYCsfvRDnnLKKZxwwglAVhWq4VZGfKh07r23tnTeffddIH/nZTUnvj7XXDUdoTVVhbkqo+LeZZddAOrr1LGquueZZx4g+2PffPNNvv71r4/zWX4/RiW533HYYYcBWRU3iqIo+PTTT4EcQXTqqacCeX+mqxhscc1uueWWQGuVuLgv5l6Mx+D5s/rqNU/xtttuC+TzbdiwYQBcddVVQO07KM9Zo+mT7ZlSOhQYBVzgS528rVPfTUpp15TS8JTS8FaGHgVBELQ7vVbkKaXtgHWAVYp8ux0BzD3W2+YCXuvs94uiGAoMhZqPvLfjGJsLLrigrlqNWlHZLLHEEgBsscUWQFYx+vJOO+00IPvJ9JH/4he/ALJSagXGrZb99j/5yU8AOPzww4Gscso4PW+88UY9akeF6A59syM99AGPGjWqHq2isl5yySUBmG662h763/72NyDPVfkzpOyPrQKqO1Wy+xrud3iMZhXqO99oo42A2v5G2dfvZ44cORLI/mWtzEbz6aef8vLLLwNw+umnA9nX392em8eiZdxo62FiOOeccwDGq3CotWBEzkwzzQTAfPPNB4xvXV199dVss802DR/v2PTqQp5SWgM4GFihKIqPx/rR1cBfUkonUtvsnB/4Z59H2Q1+8VdeeWX9ZPdLNSFBV4nuCBeUC0+zyUfDwQxLvPXWW8f5vWaie8iNyo033nicsXU3Jr+fYcOG1S9+fj8u3mZfyP3eb7zxxvrG63nnnQfk79qL3dZbbw3kDbXyhtlyyy0H5A3rKnHttdcCtZMbqLsk5phjDqAmPgC+//3vA3l9TgjFiZ+x2Wab9eOIu2fKKadk5plnBuDBBx8Exp+TsjvMRy+K++yzT/2zqoKulfLNaOmla9t8s8022zivWzzrlFNOGef3TCxqJt1eyFNKFwIrAjOllEYARwCHAF8Bho2ZsHuLoti9KIrHU0qXAE9Qc7ns2V3EShAEQdA3ur2QF0WxRScvnzWB9x8DHNOXQU0s//3vf4EcoA+w7rrrAnmDsCtUDiqDQYMGAdlUtHSl6rAVCkKlOXToUCArg7ISV227AaUyMIzqgw8+qB+vm5uah7olmmVxqCofffTRutVU3nB1LKpY1arKRwVVtraqgN/nfvvtB+R1plmu1TH//PO3YHR9RytP15BK2/Ok7J5wLk3e2m233ZoyzomhvH48pq4Keble3Qx1nb7xxhuNGmKXVC/QNgiCIJgoBkSK/p133gnUCvKoeEwO6YpnnnkGyBtsKiY3FlW3bnK2cgNNBWpCiKgADCV89tlnAeqhTyoMlYObY5CPR9XequQZN5M74/LLLwfyZpJz4nGtueaaAMw999yd/HZr0TeutVguI6Al1K5YutUN93vuuQfIG9JlP7Pra5111gHga1/7WlPGOTFsuOGGAJx00klA9n13FZrr3pXr0mP+5je/2dBxdkYo8iAIgjZnQChyEyG++OILOjo6gPHvovos3WVfeeWVgRwGtcYaawBwxx13AFn1qTxa6X814sF4+yeeeALIikF/pCrb1G0tFX3mY/st9S+b1FAlVDg777wzML6/1X0KQ7y6syaa7f8HOPHEE4Gs0oww8bHd8bv0fLMMxNhWH+Q1aXil30sVcV1pLdk4oituu+02IIcD+9iIFnDdEYo8CIKgzWlrRe4OucWVJp988npMsf4rC9pYHtRSkyYMmSBjREg5IkIl0cqGDEbSWKz/yiuvBLJS1VowDvvHP/4xkOOud9hhh/r7fa9lRt1xrxLOiXsAogrUevrud78LjJ8YVLaenn76aQAWXHBBoLH7HfqMTbQy8sE5NCHIyCNVX7s2/HD9GFf+4osvAvk8UqWa+1CluPEyWusmBbpHs9VWWwF53RgFdvzxxwP5OuT6rGQZ2yAIgqDatKcMGIM75N4BP//8c2666SYgZ2aq1i05Wc5sLD+K76tCdMECCywAZBW3+OKLA/Dtb38byKV63RdQqRvtoWJIKdV9mUbrtMJ/3B3G7ZazBR2jqq68D9LVPkYzmmhoRdxwww1Atia07FyrllNwv8M9GhWtY11hhRWAWhMJ9zyqEEFVplw2QZwrm2CsvfbaTRvTxOI6M1NTa94cgHnnnRfI55tNMB599FEgXyvKsfTNpDpnbxAEQdAr2lqRG1FifZQrrriiHs9ajnQQVc2+++4L5DK2qkCbxKqo9Lm3EhWoiqGruFaVwJ577gnAX/7yl/E+x0xC4+2rpMTF1m6OraxAnTOtrSq0rdtxxx2B3K7OOTrooIOAXGLXsq3OlXkLKluba1x66aVA7djNnnRvxJZkE9uOsGzh9AdadEZS+TfKWbmeV6raKuE+mrklHoM5AMaV+31bG6gcLeac33fffay33nrNGHqd6p3FQRAEwUTR1orcO6HKc8SIEfW7pQrHKIJyfRL9WjfffDOQqwCKbbP0XVaBrpT4Qw89BGS/qv5aIwbM/BwyZEi96USV/KyiErJmTnmu9IF//HGt4Gar29QBvP3228D4JYaNWinXUlGB22Bay8joD9evjaedS8iWiLHbE0sj5tzj7Kq2itnIlpGuIq4n57LcbNnsZ/fffL/fZzlKZb/99qs3/3D+taK8rvR3Xkoo8iAIgjanrRV5mbnmmouf/exnPXqvisHKe2NHdkDXFQarhBmfm2yyCZD9ld7tVejW92hFc96JQf9yuXGvj+4VGHvd7HZanWE0lLVDjPXvqqqhc7PYYot1+nOzVfXPnnrqqfX4d2uBVCEWW9Vq/kU55l9Uta1sJdgd5pSUG7Jbo9+oFfMRyvh7ztm7775bz90Q513r2KzQcv2k3lLdq1QQBEHQIwaUIp8YVBTGm5f9sKrcKiryPfbYA8jNXh2zflajOGzSXHUlLtaAV9mUIyD0idsxqAr1x/V9qpJt+q2a60o9q2BfeuklINewNs7fvYzVV1+93vquSmtRC9Yosa46BKnIWxFb3VPc11AdO2c2Yjfm3/hyfeJeM8qNpjujXME0fORBEATBOEyyity4V5WRd0zvxtaGaCTGSxvb3lWNZhWqNUZUCioDx7zSSisBNb8qjN9jsKqoaPTld1XT2gzXKsSNi9aO6kwrSR+5GY1m0tpI+uGHHwayylOJO4e//OUvgVoj6iopcSl3a5Jyr073PY466iggx2RXCWvFm5dizLsRRmXKatpjdg6nnHLKem2d733ve0C2Jt0D6e96LNVbIUEQBMFEMckpcuNdN910U2B8/5bq2Ey8RnL33XcDWYmakakCO+OMMwA4/fTTgVxX3DE7Vmurm/lZpdj3nqD/1Hh4q8up6lRAyy+/PFCtCAgjZ8xXUHG+9957QM5PKHeRL1uA1iTZaKONgOZUauwLrkXj3D0e12a5ppFWZXkvqgqU+4maMSzleHHnSgWvhfj73/8eqFnCza6AGIo8CIKgzRlwitw7v/5m77aqPLt3//vf/x7n97yD6strRp3uXXbZBciK1LHvs88+QK5dbS2IcpyrY61yhE1PUM19+OGHnf7cuekqVrmVqNbsPeqcqsyHDRsG5MgH5+6AAw4Acq14IyfaBWvde15J2Weu8nYNu9arWAffCBwzaLWYrbdkL84qWRPSnmd+EARBUGdAKfIRI0Zw4IEHAjkixLup8bredcu+cRVCM+uPq+ZUYyrPZ599Fhhfiftzd77181fVj9oTvvjiC0444QQg+12NPVbd6fNfc801gWofr9EJ9kKtYk/UvlIURX1uylE7WoW+rv/YGvpV2t8o49it0FjFSo1dEYo8CIKgzRlQinzGGWesK2/rOhsvXkY/V1ndGQnSCqzi+MgjjwA5wkalsOiiiwK5E3mVlWlPmWyyyRgyZAiQ9wj0TRo9oOXRVX2SoLmklOpROltssQWQrUqjcAbC2mwnQpEHQRC0OQNKkU811VR1H/gtt9wCwF577QXAyJEjgeyjW3/99YHcKbuVFfX0N5rlV1Yz+oyNU22X2ik9xTnR0gjaB7sXBa0lFHkQBEGbk8pxn+O9IaWzgXWAkUVRLFL62YHACcDMRVG8lWpS8mRgLeBjYPuiKB7obhAdHR2FdZ0nZcrV1Mp1ONo1TjyoBu65aOEF1aajo4Phw4f3aLOhJ1eGc4A1yi+mlOYGVgNeHuvlNYH5x/zbFTitJ4MIgiAIek+3t+aiKO5MKc3byY9+BxwEXDXWa+sD5xU1mX9vSmm6lNLsRVG83h+DHegYSeNjs+s1BAObK6+8EqhWh6Wgf+iVjZVSWg94tSiKh0sbc3MCY1ecGTHmtUnyQm768kC8IJcbCQwUBupxQS7NPBCPbVJnoi/kKaWpgUOBH3X2405e69QJn1LalZr7paWx20EQBO1Ob3bPvgUMAh5OKb0IzAU8kFKajZoCn3us984FvNbZhxRFMbQoio6iKDrarexqT5liiikGpBqHmqobiMpuoB4XDOxjm9SZ6At5URSPFkUxS1EU8xZFMS+1i/fgoijeAK4Gtk01lgHeC/94EARBY+nWtZJSuhBYEZgppTQCOKIoirO6ePv11EIPn6MWfrhDP40zCNoKQ/1sFzb99NMD7VeuNmgPehK1skU3P593rP8XwJ59H1YQBEHQUyIzIKgsRpCobqu431Aeo4XP9t57byC3QjMJ55lnngGoN+cNgv4gUgWDIAjanFDkkwC2SGsX/6x+5VVXXRXIpYiNuCg3Om4ljsmmGIceeigwfts6FbsNFiziZtnXKmPpiNdfr8UtPPjgg/+/vTMPlqLK0vjvKD4HWgxFwhFFBRFRNBzUVtFxa213xCUMwx0ctcNl3FckXEbFFVsdFxDRUdQBGUQH0XFpwF3BVtyR8Sk4DbaijmiEMtLCnT8yv7pF8sq38CorC84vgnivsvIVJ28u9d1zv3tuqeTwnDlzlvk5ePBgIC7oorISXl6iunjrOo7j1DmuyOsILV+3zz77ADE/+9NPPy3zulu3bkBUtv369QNg2rRphfYRS/ldfPHFQDxebRcjR44E4NprrwWKUdZXS7ydeOKJADzyyCNA7A2pENrBBx8MwBdfJNMrtKBvEVG7z5gxA4BrrrkGSBZt0WLSixYtWuZvdNxaBKV79+5AVOhnnHEGUIxztjLhitxxHKfOabaMbR7kWcZWuUopJLkJ2prDmzdvHhBVsApeVYPDDz8cgJdffhlIylwCTJkyBYjHlkUOCi1M0RSLFy8G4PLLLwfg22+/BWD06NErGnaLUS581113BeCHH34AYk9D6FypvK/UbZFUnpSq2lV1d1SoStefFtju0qVL3iE2i9p/xx13BGIPr2PHjqVrTf545czl0tFiIeoBqmfSo0cPAN5+++1l9nOWp73L2DqO4zgFZqXNkSu/J/fAaaedBoCUvxb2lWKQUpLCzhbflyrU5x155JFAzB8+99xzQFQv7cn3338PxOXrpG7effddIKo7HYtilUvluuuuq/jZclvI/6z8s/Lu+++/PxAXQK4Gil/L8knVVULHp/1Uq0fOiQ022KAqcbaGjh07ApUXI9YxaDxAy9xVs0fXWh588EEgulU0DjBgwACOPfZYALbffnsgHp8WDp88eTIATz31FABvvfUWALNnzwbifVTEnkh78tJLLwHRgbXbbrsB8XnRXot8uCJ3HMepc1Y6Ra6cpJSCcnmbb745EJdP035COeEnn3wSiIsz6+8//vhjAK666ioAXnnlFSAqEeUK2xOptqOOOgqIKlkKVl5kqTipwA033BCAqVOnAk3njtUOt99+OwATJ04E4vFmHTDV5PPPPwdi3jSLZnQqn6p2EOqhbLXVVgDMnz8fgE6dOrV/sC1EMSoHrkWKdSw6h+oRFWGsKotcQ7omlN++9NJLS+o8i9wqm266KRCP78033wRiD6W9cuNz584txVUUPvroo9J41pdffgnENpw1axbQ/r56V+SO4zh1zkqnyKWYP/30UyCqVH1rS51KMWgm2sknnwxE36tQDkvuDeWppfbkBJHib0+kLF999VUgqjiRzYWfeuqpANx8881A0yvB6DOUX5dikCrW+8pdykFSLZYsWcItt9wCxF6C1IrU69lnnw3ANtska38PGzYMiHVLFLNcFpdddhkAt956K5DvijiKpXfv3kDsLahnI4eRcsfKoWpMp0gLI++1115AHD/RWERTvU/lvDXWVKnNd9ppJ2D5uQGtRe28op/za+izGxsbAbjnnnsA+OSTTwDYfffdgXifqp0WL15c6vHreaNrWYvouCJ3HMdxlqE4X//twKxZs7jjjjuAmAPfeuutARg7diwQvz379OkDVK6oJ7X72muvAcmsSIi5zqeffhqIKrE9Uf79iiuuAKKqy6LexosvvgjEcYFfQ0qpa9euQMzhyves3OeIESOA6tfI+Oyzz3j00UeB6LXW/3nYYYcB0XWj7cqF77dfstrgd999t8xnjhs3DoCDDjpomf3yQO0pb7vQGIwUmXp0ciTpuizSTE+1vxwWuiemTJlSOifq2VVyGqlnp9nIF1xwARB958qV61puKboWevXq1aq/a4rsudI8DSls9aJ0j+ge0nbl/cvnPWif7DwBXevtjStyx3GcOmelUOTyuZ522mklpXnmmcn6FhdeeOEy+zbnLtGosnzTeq3cpRwk1VDiyvtl1U42D6hY7rrrLqBlSlxIKbzzzjsAvPDCC0BUW1KvqglSLfT/jRgxYjnnhnL+N910E7B8r0C1Y5S/V+9ISBmpF7bvvvsC+eTKpTQroZ6ijlXK/LHHHgOiYtUxL126tLRv3h5zqWRd86ojM2bMmIouG8Ut18Ypp5wCRFWvsSjVajnnnHMAGDJkCFDdcyRFrXbU/aWxlPfffx+IDjXddzom9R40t0JzLuTI0bNmzpw5pb9VG954440AVXPYuCJ3HMepc+pakcvloJojv/zyCw899BDQ+ryo1LBm2mkGmtTvAQccAMTZbtVACkEqWccnpAiUb1RuTh7VljgepBRUN1s5PKnWu+++G6h+blzKdMqUKSV1JzW2yy67AMs7iIQU1dVXXw1EtafP1DEq35yna2W99dYD4tiL8v5Cx6qf2m/48OEA3HnnnUB0uTQ2NpaOZ8899wTg8ccfB/I7LsWqPH9TalzKU7FJtQpdXxtvvDGQeNEhnkNd03K1tOexaYzp3HPPBeLsbh2PPP8ar8jWLFIvXkpd51joXOme6dChQ+nevPLKKwE45phfXTFzhXFF7jiOU+fUZfVDxazZlxo9bmhoKPm8d9hhhxZ9ltTOpEmTgJjTkzNiwoQJQHXrd8h1IYeNvN06Tn3TS81k/eTbbrstEHPmUrJZVb1w4cJS7lJeWHm05UHPq/aFjnmTTTYp9QrUo1Bs8vpXQspJTiJ9jlSuamNXs05MJR5++GEg1viRwpRyle9ax6BKjlKHaotFixaVrgOdG40J5VU5ULGqnVdbbbXStaX4tWqT5lU0p6jlCDnhhBOAqGpVAXPttddut/jVfpo5nJ3VrTEm1epR/SS5dirFovMgd5Su2zXWWKN0XKqh05b5AV790HEcZxWiLhW5FOnMmTMBOP7444FkduLOO+8MRCdDJX+qcpfXX389EBX5V199BcDzzz8PwJZbbtnyA2klyt3JhZGdqSjk4pAC098pV6fZdPLyqm60lKlyzlOnTi199vrrr7/M/9meCqglSP1svvnmpZik8nR8zakYKavOnTsD8Zyq5yIFls1p5oHuqzfeeAOI1TblxFEdE7kYsrnizz77DEjy4horUU9L8wzkSc+LjTbaCEhyyzo3conpfLY0t6326du3LxDHgzQPRGNcRaxXrlj1bJDrSq6Yrl278swzzwBxjda24IrccRxnFaIuXStSbsqDS6H06dOH6dOnA7EuhNSa1gxU/QjN5tKMOo1Ya4WcaipxodxjdmaZVE22vri+8aVg5VmWEpUil6LVdrlglixZUvpMzWxV++SN8tnlPUL1IFrql1Z9mKzft2fPnkB1KlK2lKwDR3lY1VhRLliOK3m1hXoRI0eOLDkf1AM54ogjgOhfzsu9IicGxLZWbry1MWh/VejUnACNUUmZq+5/kdaave2224CYI9f9qN7JjBkzSr3CvHBF7jiOU+fUpSLPIvXyzTffLFdPXMpP9baVu1J1OuUoVVNFSj4PlNtW/XCtTiQHQ7aGtRwCUt5S3IpZOUz5XbPrk0LMO9eiMmA55bPsFKfyoeod6fizSMUrz5wd55G7o9pe+NagcY6TTjoJiG4o5c4rsWDBgpKTRW2mHohyta2tU9JWNGN26dKlDBw4EIDzzz9/hT5T94COUW6miy66CIi9jyKsnKQetJ4hur7U89O4XN5qHFyRO47j1D0rhSIv55BDDgFi7Qr5pDWLS37wAw88EIg5uTyVuJA61np+ym3LwSBnSXPKUopbylar/owZMwaItdnLPcm1Rgq1XJFL8ci/q9x+FrWT6phnZ0lqdm4Rka9YNVaUK3/ggQcAOO6444DYU3r66adLKlXtpOtB13SlGbDtjSpj/vjjj6WVgFa0frq813J+6FrW5xZBiQv1ptRjVL0l9fZrocSFK3LHcZw6p9mvUzO7HxgALAghbFO2/Szgn4FfgKdCCBen24cAJwNLgLNDCM9WI/Dm0AxG+XLPOOMMgJKrRbNBtXJ7LZFjQbny1s4izVZnO+uss4Do3lCNifnz55cUj/zytULH2NDQUFLYUtZaEWnu3LnA8jM8pYC0MruQym3prN480biG6sIIqWydM1UFVN515syZy1W/lHsl79WE1GP6+eefSzV5bKDtnwAAChxJREFU2tr70bnWtZl1HqkWfxGQO0wuIb1WTyivHtGv0ZIr4QHgTmCMNpjZ74BDgW1DCD+b2frp9r7A0cDWwIbAn8xsixBC9dZjagZNdOnfvz8Ql2rThVQr+105iq1Scf7WohtdqYby4ls67lGjRgExxZQ3GuRqaGhYzmaph9t9990HxIEvWUVV6lVfAPr7e++9F6i8WEgtyVrVdIxKHehLWGkxPdDLH+J6yA0YMACobtmIcppaVk1trgHY1i50rWnwmrSlY9NAf7WLTLUEHa/MA0r/6Jmhwc0iWCObTa2EEF4C/jez+XTghhDCz+k+C9LthwLjQgg/hxDmAI3ATu0Yr+M4jpOhrX2zLYDdzWwY8H/AhSGEN4GNgDfK9puXbqsZSiGosLu6RbIdSgHUEnWR1V2VZXK77bYD4iKvstVJcUopLViQfI8qJaHuqo5d+zc0NJT+JjvJKC8Lm5AC69y5c2nwKBubSrpq0FN2w/IltSBO89bkkSKiWDVpROcmO7kru2ydmZVUuyyzWjAjL3SuBg0aBMANN9xQul5kmdW1qePLIqusFqdQz1jXn/4PTX4qQq9Kk5JUfE3KW9bRvEsk/BptfZB3ANYF+gM7AuPNbDOgqT5GkzYJM/sD8AcoVoM4juPUG219kM8DJoZEZswws6VA13R7uQenO/BFE39PCGEUMAqSolltjKMiUjxafik7uKcp00WYNKJveiktFbKSUleMa621FpAUmoKYI5aFS0peuT19rmxjCxcuLA1Yffjhh0CciJG3ItexXX311SWLaFZp67V6GlmUl1VhqiKjc6gB7WwvJDuAqWPr169faXk05Y1rZclTr6FDhw6la0r3lRS5yiYoxvfeew+Ig6K6tvW+JrGp3O+KTjBqDzRWJSWuHq8K6WnxiyLR1qfYE8DeAGa2BdAAfANMAo42szXNrCfQG5jRHoE6juM4TdMS++FYYC+gq5nNA64E7gfuN7MPgMXAoFSdf2hm44GPSGyJZ+btWFFZWpULleKUOlUaZ9iwYXmG1SKUg1ThLqk1/ZSKq6RAs+Vvpe723ntvICnOpb9VMXwp9LxLvep8DBw4kNGjRwPLK+/s8Qg5PLS/eipFRvnt119/HYglJLQIttxVgwcPBuJEtta6QaqJxmw6depUmsikRZOV29d5VYEtFYST40Pb1SNWSY0iuMeEJglqTEaTtIqoxEWzD/IQQiUf0PEV9h8GFO8p6TiOs5JSlwtLVKKxsbGkGpQ/Vu5XSkBOiFos/9UcGsGfNm0aEEfH5blWgSUV7cn6qIX8xVp2S2UL5s6dW1qwQJ8pJZhH2d5K6Lg1Tf2aa64BYt5YP3v16gVQyhkXYTJXW9F9p3OoXkYRxmya47XXXistrqz4FbeOSwXPdFzK72vRZU14KoIHW4wYMQKASy65BIi9BC1go5IZeeELSziO46xCrBSKXMdw+umnl2YsSgko56hRcS29VCQl0Fqy5Wmz7paWkD3v9dweTv5IvQ4fPhyIPdzzzjsPiEXo6qGHIeS8ketLM4qHDh0K5H+PuCJ3HMdZhVgpFLkIIdDY2AjEfGo9KQLHcfIn69zaY489gFjgrFa9VVfkjuM4qxAr1cISZlby6zqO47SEcePGAdGlMn78eKC+xo1ckTuO49Q5K5UidxzHaS2ayamf9YgrcsdxnDqnEK4VM/sa+JGk8FYR6YrH1haKGltR4wKPra2sjLFtGkJo0arwhXiQA5jZn0MIv611HE3hsbWNosZW1LjAY2srq3psnlpxHMepc/xB7jiOU+cU6UE+qtYB/AoeW9soamxFjQs8traySsdWmBy54ziO0zaKpMgdx3GcNlCIB7mZHWBms82s0cwurWEcG5vZNDObZWYfmtk56fYuZva8mX2S/ly3hjGubmYzzWxy+rqnmU1PY3vUzBpqFNc6ZjbBzD5O22+XorSbmZ2Xns8PzGysmf1drdrNzO43swXpMona1mQ7WcK/pvfFe2a2fQ1iuzk9p++Z2eNmtk7Ze0PS2Gab2f55x1b23oVmFsysa/o6t3arFJeZnZW2y4dmdlPZ9uq0WQihpv+A1YFPgc1IFnF+F+hbo1i6Adunv3cG/hvoC9wEXJpuvxS4sYbtdT7w78Dk9PV44Oj095HA6TWK60HglPT3BmCdIrQbsBEwB+hY1l6Da9VuwB7A9sAHZduabCfgIOC/AAP6A9NrENt+QIf09xvLYuub3qtrAj3Te3j1PGNLt28MPAt8DnTNu90qtNnvgD8Ba6av1692m1X9wm1BQ+wCPFv2eggwpNZxpbH8J7AvMBvolm7rBsyuUTzdgSnA3sDk9EL9puxGW6Ytc4xr7fRhaZntNW+39EH+F6ALSUmKycD+tWw3oEfmxm+ynYB7gGOa2i+v2DLvHQ48kv6+zH2aPkx3yTs2YALwD8Dcsgd5ru3WxPkcD/y+if2q1mZFSK3oRhPz0m01xcx6ANsB04G/DyH8FSD9me/ifZHbgIsBLS+/HrAwhPBL+rpWbbcZ8DXwb2naZ7SZ/YYCtFsIYT4wHPgf4K/A98BbFKPdRKV2Ktq98U8kShcKEJuZDQTmhxDezbxV69i2AHZPU3cvmtmO1Y6rCA/ypmpF1tRKY2ZrAY8B54YQfqhlLMLMBgALQghvlW9uYtdatF0Hku7liBDCdiTlFmo21lFOmm8+lKQruyHwG+DAJnYton2rKOcXMxsK/AI8ok1N7JZbbGbWCRgKXNHU201sy7PdOgDrkqR1LgLGW1ITt2pxFeFBPo8kzyW6A1/UKBbMbA2Sh/gjIYSJ6eavzKxb+n43YEENQvtHYKCZzQXGkaRXbgPWMTNVsaxV280D5oUQpqevJ5A82IvQbr8H5oQQvg4h/A2YCOxKMdpNVGqnQtwbZjYIGAAcF9KcQAFi60Xy5fxuek90B942sw0KENs8YGJImEHSg+5azbiK8CB/E+iduggagKOBSbUIJP3WvA+YFUL4Y9lbk4BB6e+DSHLnuRJCGBJC6B5C6EHSRlNDCMcB04Ajaxzbl8BfzKxPumkf4CMK0G4kKZX+ZtYpPb+KrebtVkaldpoEnJi6MPoD3ysFkxdmdgBwCTAwhPBT2VuTgKPNbE0z6wn0BmbkFVcI4f0QwvohhB7pPTGPxKjwJbVvtydIhBZmtgXJ4P83VLPNqjk40YrBgoNIHCKfAkNrGMduJF2d94B30n8HkeSipwCfpD+71Li99iK6VjZLL4ZG4D9IR8prEFM/4M9p2z1B0rUsRLsB/wJ8DHwAPETiGqhJuwFjSXL1fyN5+JxcqZ1IuuJ3pffF+8BvaxBbI0leV/fDyLL9h6axzQYOzDu2zPtziYOdubVbhTZrAB5Or7e3gb2r3WY+s9NxHKfOKUJqxXEcx1kB/EHuOI5T5/iD3HEcp87xB7njOE6d4w9yx3GcOscf5I7jOHWOP8gdx3HqHH+QO47j1Dn/D4yiL3wDIqm+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "n = 6\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i in range(n):\n",
    "    # Noise input.\n",
    "    z = np.random.normal(-1., 1., size=[n, noise_dim]).astype(np.float32)\n",
    "    # Generate image from noise.\n",
    "    g = generator(z).numpy()\n",
    "    # Rescale to original [0, 1]\n",
    "    g = (g + 1.) / 2\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1CUZ0dkOo_F"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "qmkj-80IHxnd"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds4o1h4WHz9U"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/cyclegan\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/cyclegan.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/cyclegan.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver cdigo fuente en GitHub</a>\n",
    "</td>\n",
    "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/cyclegan.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITZuApL56Mny"
   },
   "source": [
    "En este cuaderno se ensea la traduccin de imagen a imagen no emparejadas con la red condicional de GAN, como se describe en [Traduccin de imagen a imagen no emparejadas con las redes adversarias de ciclo constante](https://arxiv.org/abs/1703.10593), tambin conocido como CycleGAN. En el artculo se propone un mtodo que puede capturar las caractersticas del dominio de una imagen y resolver cmo se podran traducir estas caractersticas en el dominio de otra imagen, todo en ausencia de ejemplos de entrenamiento emparejados.\n",
    "\n",
    "En este cuaderno se asume que usted tiene conocimientos de Pix2Pix, que puede aprenderlo en el [Tutorial de Pix2Pix](https://www.tensorflow.org/tutorials/generative/pix2pix). El cdigo de CycleGAN es similar, la diferencia principal es la funcin de prdida adicional y el uso de datos de entrenamiento no emparejados.\n",
    "\n",
    "CycleGAN usa una prdida de consistencia del ciclo para poder entrenarla sin datos emparejados. En otras palabras, puede traducir de un dominio a otro sin un mapeo de uno a uno entre el dominio de origen y el de destino.\n",
    "\n",
    "Esto expande las posibilidades de hacer muchas tareas interesantes como mejorar fotografas, colorizar imgenes, transferir estilos, etc. Todo lo que necesita es un conjunto de datos de origen y uno de destino (que son simplemente directorios de imgenes).\n",
    "\n",
    "![Output Image 1](images/horse2zebra_1.png) ![Output Image 2](images/horse2zebra_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Preparacin de la canalizacin de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fGHWOKPX4ta"
   },
   "source": [
    "Instale el paquete [tensorflow_examples](https://github.com/tensorflow/examples) que permite importar el generador y el discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJ1ROiQxJ-vY"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhSsUx9Nyb3t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Canalizacin de entrada\n",
    "\n",
    "En este tutorial, se entrena un modelo para traducir desde imgenes de caballos a imgenes de cebras. Puede encontrar este conjunto de datos y otros similares [aqu](https://www.tensorflow.org/datasets/catalog/cycle_gan).\n",
    "\n",
    "Como se menciona en el [artculo](https://arxiv.org/abs/1703.10593), aplique irregularidades y rplicas aleatorias en el conjunto de datos de entrenamiento. Estas son algunas de las tcnicas de aumento de imagen que evitan el sobreajuste.\n",
    "\n",
    "Es similar a lo que se hace en [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix#load_the_dataset)\n",
    "\n",
    "- Al aplicar irregularidades de forma aleatoria, se cambia el tamao de la imagen a `286 x 286` y se recorta aleatoriamente a `256 x 256`.\n",
    "- Al aplicar reflejos de forma aleatoria, se voltea la imagen horizontalmente de forma aleatoria, es decir, de izquierda a derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n",
    "                              with_info=True, as_supervised=True)\n",
    "\n",
    "train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n",
    "test_horses, test_zebras = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image, label):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_test(image, label):\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsajGXxd5JkZ"
   },
   "outputs": [],
   "source": [
    "train_horses = train_horses.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_zebras = train_zebras.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_horses = test_horses.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_zebras = test_zebras.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3MhJ3zVLPan"
   },
   "outputs": [],
   "source": [
    "sample_horse = next(iter(train_horses))\n",
    "sample_zebra = next(iter(train_zebras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pOYjMk_KfIB"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Horse')\n",
    "plt.imshow(sample_horse[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Horse with random jitter')\n",
    "plt.imshow(random_jitter(sample_horse[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KJyB9ENLb2y"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Zebra')\n",
    "plt.imshow(sample_zebra[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Zebra with random jitter')\n",
    "plt.imshow(random_jitter(sample_zebra[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## Importar y reusar los modelos Pix2Pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGrL73uCd-_M"
   },
   "source": [
    "Importe el generador y el discriminador que se usa en [Pix2Pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) a travs del paquete instalado [tensorflow_examples](https://github.com/tensorflow/examples).\n",
    "\n",
    "La arquitectura del modelo que se usa en este tutorial es muy similar a la que se usa en [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). Estas son algunas de las diferencias:\n",
    "\n",
    "- Cyclegan usa la [normalizacin de instancias](https://arxiv.org/abs/1607.08022) en vez de la [normalizacin de lotes](https://arxiv.org/abs/1502.03167).\n",
    "- En el [artculo de CycleGAN](https://arxiv.org/abs/1703.10593) se usa un generador basado en `resnet`. En este tutorial se usa un generador `unet` por la simplicidad.\n",
    "\n",
    "Se entrenarn 2 generadores (G y F) y 2 discriminadores (X e Y).\n",
    "\n",
    "- El generador `G` aprende a transformar la imagen`X` en la imagen `Y`. $(G: X -> Y)$\n",
    "- El generador `F` aprende a transformar la imagen `Y` en la imagen `X`. $(F: Y -> X)$\n",
    "- El discriminador `D_X` aprende a diferenciar entre la imagen `X` y la imagen generada `X` (`F(Y)`).\n",
    "- El discriminador `D_Y` aprende a diferenciar entre la imagen `Y` y la imagen generada `Y` (`G(X)`).\n",
    "\n",
    "![Cyclegan model](images/cyclegan_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ju9Wyw87MRW"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDaGZ3WpZUyw"
   },
   "outputs": [],
   "source": [
    "to_zebra = generator_g(sample_horse)\n",
    "to_horse = generator_f(sample_zebra)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_horse, to_zebra, sample_zebra, to_horse]\n",
    "title = ['Horse', 'To Zebra', 'Zebra', 'To Horse']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i])\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "  else:\n",
    "    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5MhJmxyZiy9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real zebra?')\n",
    "plt.imshow(discriminator_y(sample_zebra)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real horse?')\n",
    "plt.imshow(discriminator_x(sample_horse)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Funciones de prdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRqt02lupRn8"
   },
   "source": [
    "En CycleGAN, no hay datos emparejados con los que entrenar, por eso no hay garanta de que la pareja de la entrada `x` y de la salida `y` sea significativa durante el entrenamiento. Por eso. para reforzar que la red aprenda a mapear correctamente, los autores proponen la prdida de consistencia del ciclo.\n",
    "\n",
    "La prdida del discriminador y la prdida del generador son similares a las que se usan en [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix#build_the_generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "  real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "  return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iIWQzVF7f9e"
   },
   "source": [
    "La consistencia del ciclo significa que los resultados deberan ser casi igual a la entrada original. Por ejemplo, si se traduce una oracin del ingls al francs y luego se vuelve a traducir del francs al ingls, la oracin resultante debera ser igual a la oracin original.\n",
    "\n",
    "En la prdida de consistencia del ciclo,\n",
    "\n",
    "- Se pasa la imagen $X$ por el generador $G$ que genera la imagen $\\hat{Y}$.\n",
    "- La imagen generada $\\hat{Y}$ se pasa por el generador $F$ que nos da la imagen del ciclo $\\hat{X}$.\n",
    "- Se calcula el error absoluto de la media entre $X$ y $\\hat{X}$.\n",
    "\n",
    "$$forward\\ cycle\\ consistency\\ loss: X -> G(X) -> F(G(X)) \\sim \\hat{X}$$\n",
    "\n",
    "$$backward\\ cycle\\ consistency\\ loss: Y -> F(Y) -> G(F(Y)) \\sim \\hat{Y}$$\n",
    "\n",
    "![Cycle loss](images/cycle_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMpVGj_sW6Vo"
   },
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "  \n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-tJL-fX0Mq7"
   },
   "source": [
    "Como se mostr anteriormente, el generador $G$ tiene que traducir la imagen $X$ a la imagen $Y$. Segn la prdida de identidad, si se ingresa la imagen  $Y$ en el generador $G$, debera dar la imagen real $Y$ o algo que sea muy parecido a la $Y$.\n",
    "\n",
    "Si ejecuta el modelo de cebra a caballo en un caballo o el modelo de caballo a cebra en una cebra, la imagen no se debera modificar tanto si la imagen ya contiene la clase de destino.\n",
    "\n",
    "$$Identity\\ loss = |G(Y) - Y| + |F(X) - X|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05ywEH680Aud"
   },
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "  return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-vjRM7IffTT"
   },
   "source": [
    "Inicialice los optimizadores para todos los generadores y discriminadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Puntos de verificacin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Nota: Este modelo de ejemplo es entrenado para menos pocas (10) que en el artculo (200) para que la duracin de entrenamiento de este tutorial sea prudente. Las imgenes generadas tendrn mucha menos calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "  prediction = model(test_input)\n",
    "    \n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_input[0], prediction[0]]\n",
    "  title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE47ERn5fyLC"
   },
   "source": [
    "A pesar de que el bucle de entrenamiento parece complicado, consiste en cuatro pasos bsicos:\n",
    "\n",
    "- Obtener las predicciones.\n",
    "- Calcular la prdida.\n",
    "- Calcular los gradientes con la retropropagacin.\n",
    "- Aplicar los gradientes en el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "  # persistent is set to True because the tape is used more than\n",
    "  # once to calculate the gradients.\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    # Generator G translates X -> Y\n",
    "    # Generator F translates Y -> X.\n",
    "    \n",
    "    fake_y = generator_g(real_x, training=True)\n",
    "    cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "    fake_x = generator_f(real_y, training=True)\n",
    "    cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "    # same_x and same_y are used for identity loss.\n",
    "    same_x = generator_f(real_x, training=True)\n",
    "    same_y = generator_g(real_y, training=True)\n",
    "\n",
    "    disc_real_x = discriminator_x(real_x, training=True)\n",
    "    disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "    # calculate the loss\n",
    "    gen_g_loss = generator_loss(disc_fake_y)\n",
    "    gen_f_loss = generator_loss(disc_fake_x)\n",
    "    \n",
    "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "    \n",
    "    # Total generator loss = adversarial loss + cycle loss\n",
    "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "  \n",
    "  # Calculate the gradients for generator and discriminator\n",
    "  generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "  generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "  \n",
    "  discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "  discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer\n",
    "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "  \n",
    "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "  \n",
    "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  n = 0\n",
    "  for image_x, image_y in tf.data.Dataset.zip((train_horses, train_zebras)):\n",
    "    train_step(image_x, image_y)\n",
    "    if n % 10 == 0:\n",
    "      print ('.', end='')\n",
    "    n += 1\n",
    "\n",
    "  clear_output(wait=True)\n",
    "  # Using a consistent image (sample_horse) so that the progress of the model\n",
    "  # is clearly visible.\n",
    "  generate_images(generator_g, sample_horse)\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "\n",
    "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "## Generar con el conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUgSnmy2nqSP"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in test_horses.take(5):\n",
    "  generate_images(generator_g, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABGiHY6fE02b"
   },
   "source": [
    "## Prximos pasos\n",
    "\n",
    "En este tutorial se muestra cmo implementar CycleGAN a partir del generador y el discriminador que se implementan en el tutorial de [Pix2Pix](https://www.tensorflow.org/tutorials/generative/pix2pix). Su prximo paso a tomar puede ser usar diferentes conjuntos de datos de [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/cycle_gan).\n",
    "\n",
    "Tambin puede probar entrenarlo para ms pocas para mejorar los resultados o puede implementar el generador ResNet modificado que se usa en el [artculo](https://arxiv.org/abs/1703.10593) en vez de usar el generador U-Net que se usa aqu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jQ1tEQCxwRx"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "V_sgB_5dx1f1"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# Redes generativas adversarias convolucionales profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TD5ZrvEMbhZ"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/dcgan\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/dcgan.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Ejecutar en Google Colab</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/dcgan.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     Ver cdigo fuente en GitHub</a>\n",
    "</td>\n",
    "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/dcgan.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITZuApL56Mny"
   },
   "source": [
    "En este tutorial se ensea como generar imgenes de cifras escritas a mano con la [red generativa adversaria convolucional profunda](https://arxiv.org/pdf/1511.06434.pdf) (DCGAN, por sus siglas en ingls). El cdigo se escribe con la [API secuencial de Keras](https://www.tensorflow.org/guide/keras) con un bucle de entrenamiento `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MbKJY38Puy9"
   },
   "source": [
    "## Qu son las redes GAN?\n",
    "\n",
    "Actualmente, las [redes generativas adversarias](https://arxiv.org/abs/1406.2661) (GAN, por sus siglas en ingls) son una de las ideas ms interesantes en ciencias de la computacin. Se entrenan dos modelos en simultneo mediante un proceso adversario. Un *generador* (\"el artista\") aprende a crear imgenes que parecen reales, mientras que un *discriminador* (\"el crtico de arte\") aprende a diferenciar entre las imgenes reales y las falsas.\n",
    "\n",
    "![A diagram of a generator and discriminator](./images/gan1.png)\n",
    "\n",
    "Durante el entrenamiento, el *generador* es cada vez ms bueno en crear imgenes que parecen reales, mientras que el *discriminador* es cada vez ms bueno en notar la diferencia. El proceso encuentra un equilibrio cuando el *discriminador* ya no puede diferenciar entre las imgenes reales y las falsas.\n",
    "\n",
    "![A second diagram of a generator and discriminator](./images/gan2.png)\n",
    "\n",
    "En este cuaderno, se explica este proceso en un conjunto de datos MNIST. La siguiente animacin muestra una serie de imgenes producidas por el *generador* durante un entrenamiento para 50 pocas. Al principio, las imgenes son ruido aleatorio y, con el tiempo, comienzan a lucir ms como cifras escritas a mano.\n",
    "\n",
    "![sample output](https://tensorflow.org/images/gan/dcgan.gif)\n",
    "\n",
    "Para ms informacin sobre las redes GAN, vea el curso de [introduccin de aprendizaje profundo](http://introtodeeplearning.com/) de MIT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "### Preparacin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "# To generate GIFs\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### Cargar y preparar el conjunto de datos\n",
    "\n",
    "Usar el conjunto de datos para entrenar el generador y el discriminador. El generador generar cifras escritas a mano que se parezcan a los datos de MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Crear los modelos\n",
    "\n",
    "El generador y el discriminador se definen mediante el uso de la [API secuencial de Keras](https://www.tensorflow.org/guide/keras#sequential_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### El generador\n",
    "\n",
    "El generador usa las capas `tf.keras.layers.Conv2DTranspose` (aumento de la resolucin) para producir una imagen a partir de un valor de inicializacin (ruido aleatorio). Comience con una capa `Dense` que tome este valor de inicializacin como entrada, luego aumente la resolucin varias veces hasta alcanzar el tamao de imagen deseado de 28x28x1. Note la activacin de `tf.keras.layers.LeakyReLU` para cada capa, excepto en la capa externa que usa tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "Use el generador (sin entrenamiento an) para crear una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### El discriminador\n",
    "\n",
    "El discriminador es un clasificador de imgenes basadas en la red neuronal convolucional (CNN, por sus siglas en ingls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhPneagzCaQv"
   },
   "source": [
    "Use el discriminador (sin entrenar an) para clasificar las imgenes generadas en reales o falsas. El modelo ser entrenado para que tenga como salida valores positivos para las imgenes reales y valores negativos para las imgenes falsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Definir la prdida y los optimizadores\n",
    "\n",
    "Defina las funciones de prdida y los optimizadores para ambos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### Prdida del discriminador\n",
    "\n",
    "Este mtodo cuantifica qu tan bueno es el discriminador para distinguir entre imgenes reales y falsas. Compara las predicciones del discriminador sobre las imgenes reales en un arreglo de nmeros 1 y las predicciones del discriminador sobre las imgenes falsas (generadas) en un arreglo de nmeros 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### Prdida del generador\n",
    "\n",
    "La prdida del generador cuantifica qu tan bueno es para engaar al discriminador. De forma intuitiva, si el generador funciona bien, el discriminador clasificar a las imgenes reales en falsas (o con el nmero 1). Ahora, compare las decisiones del discriminador sobre las imgenes generadas en un arreglo de nmeros 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "Los optimizadores del discriminador y del generador son diferentes ya que se entrenarn dos redes por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### Guardar puntos de verificacin\n",
    "\n",
    "En este cuaderno tambin se ensear cmo guardar y recuperar modelos, lo cual es til en caso de que se interrumpa una tarea de ejecucin larga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Definir el bucle de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jylSonrqSWfi"
   },
   "source": [
    "El bucle de entrenamiento comienza cuando el generador recibe un valor de inicializacin aleatorio como entrada. Ese valor se usa para producir una imagen. Luego, se usa el discriminador para clasificar imgenes reales (extradas del conjunto de datos de entrenamiento) e imgenes falsas (producidas por el generador). Se calcula la prdida para cada uno de estos modelos y se usan los gradientes para actualizar el generador y el discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**Generar y guardar imgenes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "Llame al mtodo `train()` que se defini anteriormente para entrenar el generador y el discriminador de forma simultnea. Nota: entrenar las redes GAN puede ser complicado. Es importante que el generador y el discriminador no se superpongan (por ejemplo, que sean entrenados al mismo ritmo).\n",
    "\n",
    "Al principio del entrenamiento, las imgenes generadas lucirn como ruido aleatorio. A medida que el entrenamiento avanza, las cifras generadas se vern cada vez ms reales. Luego de 50 pocas, se vern como las cifras del MNIST. Esto puede tardar un minuto/poca con la configuracin predeterminada en Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "Restaurar el ltimo punto de verificacin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## Crear un GIF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywiH3nL8guF"
   },
   "source": [
    "Use `imageio` para crear un gif animado para usar imgenes que se guardaron durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBwyU6t2Wf3g"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6qC-SbjK0yW"
   },
   "source": [
    "## Prximos pasos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjjkT9KAK6H7"
   },
   "source": [
    "En este tutorial se mostr el cdigo completo necesario para escribir y entrenar una red GAN. El siguiente paso que tome puede ser experimentar con diferentes conjuntos de datos, por ejemplo, el conjunto de datos de atributos de las caras de celebridades a gran escala (CelebA) [disponible en Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset). Para ms informacin sobre las redes GAN, vea el [Tutorial de NIPS 2016: Redes generativas adversarias](https://arxiv.org/abs/1701.00160).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1CUZ0dkOo_F"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "qmkj-80IHxnd"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# pix2pix: Traduccin de imagen a imagen con un GAN condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds4o1h4WHz9U"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/pix2pix\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
    "</td>\n",
    "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITZuApL56Mny"
   },
   "source": [
    "En este tutorial se muestra cmo construir y entrenar una red generativa condicional adversarial (cGAN) llamada pix2pix, la cual aprende un mapeo desde las imgenes de entrada a las de salida, como se describe en [Image-to-image translation with conditional adversarial networks](https://arxiv.org/abs/1611.07004){:.external} de Isola et al. (2017). pix2pix no es especfico de una determinada aplicacin, sino que puede aplicarse a una amplia gama de tareas, como sintetizar fotos a partir de mapas de etiquetas, generar fotos coloreadas a partir de imgenes en blanco y negro, convertir fotos de Google Maps en imgenes areas e incluso transformar bocetos en fotos.\n",
    "\n",
    "En este ejemplo, su red generar imgenes de fachadas de edificios utilizando la base de datos [CMP Facade Database](http://cmp.felk.cvut.cz/~tylecr1/facade/) proporcionada por el [Center for Machine Perception](http://cmp.felk.cvut.cz/){:.external} de la [Universidad Tcnica Checa de Praga](https://www.cvut.cz/){:.external}. Para abreviar, utilizar una copia [preprocesada](https://efrosgans.eecs.berkeley.edu/pix2pix/datasets/){:.external} de este conjunto de datos creado por los autores de pix2pix.\n",
    "\n",
    "En el cGAN pix2pix, se condiciona a las imgenes de entrada y se generan las imgenes de salida correspondientes. Los cGAN se propusieron por primera vez en [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) (Mirza y Osindero, 2014)\n",
    "\n",
    "La arquitectura de tu red incluir:\n",
    "\n",
    "- Un generador con una arquitectura basada en [U-Net](https://arxiv.org/abs/1505.04597){:.external}.\n",
    "- Un discriminador representado por un clasificador PatchGAN convolucional (propuesto en el documento [pix2pix](https://arxiv.org/abs/1611.07004){:. external}).\n",
    "\n",
    "Tenga en cuenta que cada poca puede tardar unos 15 segundos en una sola GPU V100.\n",
    "\n",
    "A continuacin se muestran algunos ejemplos de la salida generada por el cGAN pix2pix despus de entrenar durante 200 pocas en el conjunto de datos de fachadas (80,000 pasos).\n",
    "\n",
    "![sample output_1](https://www.tensorflow.org/images/gan/pix2pix_1.png) ![sample output_2](https://www.tensorflow.org/images/gan/pix2pix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Importar TensorFlow y otras bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Cargar el conjunto de datos\n",
    "\n",
    "Descargue los datos de la base de datos de fachadas CMP (30MB). Los conjuntos de datos adicionales estn disponibles en el mismo formato [aqu](http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/){:.external}. En Colab puede seleccionar otros conjuntos de datos en el men desplegable. Tenga en cuenta que algunos de los otros conjuntos de datos son significativamente mayores (`edges2handbags` tiene un tamao de 8 GB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp6IAZvEShNf"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"facades\" #@param [\"cityscapes\", \"edges2handbags\", \"edges2shoes\", \"facades\", \"maps\", \"night2day\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kn-k8kTXuAlv"
   },
   "outputs": [],
   "source": [
    "_URL = f'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{dataset_name}.tar.gz'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    fname=f\"{dataset_name}.tar.gz\",\n",
    "    origin=_URL,\n",
    "    extract=True)\n",
    "\n",
    "path_to_zip  = pathlib.Path(path_to_zip)\n",
    "\n",
    "PATH = path_to_zip.parent/dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V67lt3BFb2iN"
   },
   "outputs": [],
   "source": [
    "list(PATH.parent.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fUzsnerj1P3"
   },
   "source": [
    "Cada imagen original es de tamao `256 x 512` y contiene dos imgenes `256 x 256`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGY1kiptguTQ"
   },
   "outputs": [],
   "source": [
    "sample_image = tf.io.read_file(str(PATH / 'train/1.jpg'))\n",
    "sample_image = tf.io.decode_jpeg(sample_image)\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJ2sO8Izg7QV"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A5SU-qxPAqd"
   },
   "source": [
    "Es necesario separar las imgenes reales de las fachadas de los edificios de las imgenes de las etiquetas de arquitectura, todas ellas de tamao `256 x 256`.\n",
    "\n",
    "Defina una funcin que cargue archivos de imagen y d como salida dos tensores de imgenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO9ZAGH5K3SY"
   },
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "  # Read and decode an image file to a uint8 tensor\n",
    "  image = tf.io.read_file(image_file)\n",
    "  image = tf.io.decode_jpeg(image)\n",
    "\n",
    "  # Split each image tensor into two tensors:\n",
    "  # - one with a real building facade image\n",
    "  # - one with an architecture label image \n",
    "  w = tf.shape(image)[1]\n",
    "  w = w // 2\n",
    "  input_image = image[:, w:, :]\n",
    "  real_image = image[:, :w, :]\n",
    "\n",
    "  # Convert both images to float32 tensors\n",
    "  input_image = tf.cast(input_image, tf.float32)\n",
    "  real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5ByHTlfE06P"
   },
   "source": [
    "Represente una muestra de las imgenes de entrada (imagen de la etiqueta de arquitectura) y reales (foto de la fachada del edificio):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OLHMpsQ5aOv"
   },
   "outputs": [],
   "source": [
    "inp, re = load(str(PATH / 'train/100.jpg'))\n",
    "# Casting to int for matplotlib to display the images\n",
    "plt.figure()\n",
    "plt.imshow(inp / 255.0)\n",
    "plt.figure()\n",
    "plt.imshow(re / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVuZQTfI_c-s"
   },
   "source": [
    "Tal y como se describe en el documento [pix2pix](https://arxiv.org/abs/1611.07004){:.external}, es necesario aplicar el jittering aleatorio y el reflejo para preprocesar el conjunto de entrenamiento.\n",
    "\n",
    "Defina varias funciones que:\n",
    "\n",
    "1. Cambie el tamao de cada imagen `256 x 256` a un alto y ancho mayores-`286 x 286`.\n",
    "2. Recrtelo aleatoriamente a `256 x 256`.\n",
    "3. D la vuelta a la imagen horizontalmente de forma aleatoria, es decir, de izquierda a derecha (reflejo aleatorio).\n",
    "4. Normalice las imgenes al rango `[-1, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "# The facade training set consist of 400 images\n",
    "BUFFER_SIZE = 400\n",
    "# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
    "BATCH_SIZE = 1\n",
    "# Each image is 256x256 in size\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwwYQpu9FzDu"
   },
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "  input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "def random_crop(input_image, real_image):\n",
    "  stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image[0], cropped_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(input_image, real_image):\n",
    "  input_image = (input_image / 127.5) - 1\n",
    "  real_image = (real_image / 127.5) - 1\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(input_image, real_image):\n",
    "  # Resizing to 286x286\n",
    "  input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "  # Random cropping back to 256x256\n",
    "  input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    # Random mirroring\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfAQbzy799UV"
   },
   "source": [
    "Puede inspeccionar parte de la salida preprocesada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0OGdi6D92kM"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(4):\n",
    "  rj_inp, rj_re = random_jitter(inp, re)\n",
    "  plt.subplot(2, 2, i + 1)\n",
    "  plt.imshow(rj_inp / 255.0)\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E9LGq3WBmsh"
   },
   "source": [
    "Despus de comprobar que la carga y el preprocesamiento funcionan, definamos un par de funciones de ayudante que carguen y preprocesen los conjuntos de entrenamiento y de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "  input_image, real_image = load(image_file)\n",
    "  input_image, real_image = random_jitter(input_image, real_image)\n",
    "  input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "  input_image, real_image = load(image_file)\n",
    "  input_image, real_image = resize(input_image, real_image,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "  input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIGN6ouoQxt3"
   },
   "source": [
    "## Cree una canalizacin de entrada con `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQHmYSmk8b4b"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(str(PATH / 'train/*.jpg'))\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS9J0yA58b4g"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  test_dataset = tf.data.Dataset.list_files(str(PATH / 'test/*.jpg'))\n",
    "except tf.errors.InvalidArgumentError:\n",
    "  test_dataset = tf.data.Dataset.list_files(str(PATH / 'val/*.jpg'))\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Construya el generador\n",
    "\n",
    "El generador de su cGAN pix2pix es un [U-Net](https://arxiv.org/abs/1505.04597)*modificado* {:.external}. Una U-Net consta de un codificador (downsampler) y un decodificador (upsampler). (Puede encontrar ms informacin al respecto en el tutorial [Segmentacin de imgenes](../images/segmentation.ipynb) y en la pgina web del proyecto [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/){:.external}).\n",
    "\n",
    "- Cada bloque del codificador es Convolution -&gt; Batch normalization -&gt; Leaky ReLU\n",
    "- Cada bloque del descodificador es Transposed convolution -&gt; Batch normalization -&gt; Dropout (aplicado a los 3 primeros bloques) -&gt; ReLU\n",
    "- Hay conexiones de omisin entre el codificador y el decodificador (como en la U-Net)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MQPuBCgtldI"
   },
   "source": [
    "Defina el reductor de muestreo o downsampler (codificador):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqqvWxlw8b4l"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R09ATE_SH9P"
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6_uCZCppTh7"
   },
   "outputs": [],
   "source": [
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(tf.expand_dims(inp, 0))\n",
    "print (down_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFI_Pa52tjLl"
   },
   "source": [
    "Defina el amplificador de muestreo o upsampler (decodificador):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhgDsHClSQzP"
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz-ahSdsq0Oc"
   },
   "outputs": [],
   "source": [
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "print (up_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueEJyRVrtZ-p"
   },
   "source": [
    "Defina el generador con el \"downsampler\" y el \"upsampler\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFPI4Nu-8b4q"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "  down_stack = [\n",
    "    downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
    "    downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
    "    downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
    "    downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
    "    downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
    "    downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
    "    downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
    "    downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "    upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
    "    upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
    "    upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
    "    upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4PKwrcQFYvF"
   },
   "source": [
    "Visualice la arquitectura del modelo generador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIbRPFzjmV85"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8kbgTK8FcPo"
   },
   "source": [
    "Pruebe el generador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1N1_obwtdQH"
   },
   "outputs": [],
   "source": [
    "gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
    "plt.imshow(gen_output[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpDPEQXIAiQO"
   },
   "source": [
    "### Defina la prdida del generador\n",
    "\n",
    "Las GAN aprenden que una prdida se adapta a los datos, mientras que las cGAN aprenden una prdida estructurada que penaliza una posible estructura que difiera de la salida de la red y de la imagen objetivo, como se describe en el documento [pix2pix](https://arxiv.org/abs/1611.07004){:.external}.\n",
    "\n",
    "- La prdida del generador es una prdida de entropa cruzada sigmoidea de las imgenes generadas y un **arreglo de unos**.\n",
    "- El documento pix2pix tambin menciona la prdida L1, que es un MAE (error promedio absoluto) entre la imagen generada y la imagen objetivo.\n",
    "- Esto permite que la imagen generada se asemeje estructuralmente a la imagen objetivo.\n",
    "- La frmula para calcular la prdida total del generador es `gan_loss + LAMBDA * l1_loss`, donde `LAMBDA = 100`. Este valor se decidi por los autores del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  # Mean absolute error\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSZbDgESHIV6"
   },
   "source": [
    "El procedimiento de entrenamiento del generador es el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlB-XMY5Awj9"
   },
   "source": [
    "![Generator Update Image](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gen.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTKZfoaoEF22"
   },
   "source": [
    "## Construya el discriminador\n",
    "\n",
    "El discriminador en el cGAN pix2pix es un clasificador PatchGAN convolucional: intente clasificar si cada imagen *patch* es real o no es real, como se describe en el documento [pix2pix](https://arxiv.org/abs/1611.07004){:.external}.\n",
    "\n",
    "- Cada bloque del discriminador es Convolution -&gt; Batch normalization -&gt; Leaky ReLU.\n",
    "- La forma de la salida despus de la ltima capa es `(batch_size, 30, 30, 1)`.\n",
    "- Cada parche de imagen `30 x 30` de la salida clasifica una porcin `70 x 70` de la imagen de entrada.\n",
    "- El discriminador recibe 2 entradas:\n",
    "    - La imagen de entrada y la imagen objetivo, que deben clasificarse como reales.\n",
    "    - La imagen de entrada y la imagen generada (la salida del generador), que debe clasificarse como falsa.\n",
    "    - Utilice `tf.concat([inp, tar], axis=-1)` para concatenar estas 2 entradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIuTeGL5v45m"
   },
   "source": [
    "Vamos a definir el discriminador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ll6aNeQx8b4v"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
    "\n",
    "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
    "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
    "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdV9yAbBHNkg"
   },
   "source": [
    "Visualice la arquitectura del modelo discriminador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHoUui4om-Ev"
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ps7nIHigHYc7"
   },
   "source": [
    "Pruebe el discriminador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOqg1dhUAWoD"
   },
   "source": [
    "### Defina la prdida del discriminador\n",
    "\n",
    "- La funcin `discriminator_loss` toma 2 entradas: **imgenes reales** e **imgenes generadas**.\n",
    "- `real_loss` es una prdida de entropa cruzada sigmoidea de las **imgenes reales** y un **arreglo de unos (ya que stas son las imgenes reales)**.\n",
    "- `generated_loss` es una prdida de entropa cruzada sigmoide de las **imgenes generadas** y un **arreglo de ceros (ya que stas son las imgenes falsas)**.\n",
    "- La `total_loss` es la suma de `real_loss` y `generated_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ede4p2YELFa"
   },
   "source": [
    "A continuacin se muestra el procedimiento de entrenamiento del discriminador.\n",
    "\n",
    "Para obtener ms informacin sobre la arquitectura y los hiperparmetros, puede consultar el documento [pix2pix](https://arxiv.org/abs/1611.07004){:.external}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS9sHa-1BoAF"
   },
   "source": [
    "![Discriminator Update Image](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/dis.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Defina los optimizadores y un salvador de puntos de verificacin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbHFNexF0x6O"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Generar imgenes\n",
    "\n",
    "Escriba una funcin para trazar algunas imgenes durante el entrenamiento.\n",
    "\n",
    "- Pasar imgenes del equipo de pruebas al generador.\n",
    "- A continuacin, el generador traducir la imagen de entrada a la de salida.\n",
    "- El ltimo paso consiste en representar grficamente las predicciones y *voila*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb0QQFHF-JfS"
   },
   "source": [
    "Nota: El `training=True` es intencional aqu ya que usted quiere las estadsticas por lotes, mientras ejecuta el modelo en el conjunto de datos de prueba. Si utiliza `training=False`, obtendr las estadsticas acumuladas aprendidas del conjunto de datos de entrenamiento (que no desea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "  prediction = model(test_input, training=True)\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  display_list = [test_input[0], tar[0], prediction[0]]\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # Getting the pixel values in the [0, 1] range to plot.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gipsSEoZIG1a"
   },
   "source": [
    "Pruebe la funcin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Fc4NzT-DgEx"
   },
   "outputs": [],
   "source": [
    "for example_input, example_target in test_dataset.take(1):\n",
    "  generate_images(generator, example_input, example_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLKOG55MErD0"
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "- Para cada entrada de ejemplo se genera una salida.\n",
    "- El discriminador recibe como primera entrada la `input_image` y la imagen generada. La segunda entrada es la `input_image` y la `target_image`.\n",
    "- A continuacin, calcule la prdida del generador y del discriminador.\n",
    "- A continuacin, calcule los gradientes de prdida con respecto a las variables generadoras y discriminadoras (entradas) y aplquelos al optimizador.\n",
    "- Por ltimo, registre las prdidas en TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNNMDBNH12q-"
   },
   "outputs": [],
   "source": [
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, step):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n",
    "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n",
    "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)\n",
    "    tf.summary.scalar('disc_loss', disc_loss, step=step//1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx7s-vBHFKdh"
   },
   "source": [
    "El bucle de entrenamiento propiamente dicho. Como este tutorial puede ejecutarse con ms de un conjunto de datos, y stos varan mucho en tamao, el bucle de entrenamiento est configurado para trabajar por pasos en vez de por pocas.\n",
    "\n",
    "- Itera sobre el nmero de pasos.\n",
    "- Cada 10 pasos imprime un punto (`.`).\n",
    "- Cada 1,000 pasos: borre la pantalla y ejecute `generate_images` para mostrar el progreso.\n",
    "- Cada 5,000 pasos: guarde un punto de verificacin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFyPlBWv1B5j"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, steps):\n",
    "  example_input, example_target = next(iter(test_ds.take(1)))\n",
    "  start = time.time()\n",
    "\n",
    "  for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n",
    "    if (step) % 1000 == 0:\n",
    "      display.clear_output(wait=True)\n",
    "\n",
    "      if step != 0:\n",
    "        print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n",
    "\n",
    "      start = time.time()\n",
    "\n",
    "      generate_images(generator, example_input, example_target)\n",
    "      print(f\"Step: {step//1000}k\")\n",
    "\n",
    "    train_step(input_image, target, step)\n",
    "\n",
    "    # Training step\n",
    "    if (step+1) % 10 == 0:\n",
    "      print('.', end='', flush=True)\n",
    "\n",
    "\n",
    "    # Save (checkpoint) the model every 5k steps\n",
    "    if (step + 1) % 5000 == 0:\n",
    "      checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wozqyTh2wmCu"
   },
   "source": [
    "Este bucle de entrenamiento guarda registros que puede ver en TensorBoard para supervisar el progreso del entrenamiento.\n",
    "\n",
    "Si trabaja en una mquina local, lanzara un proceso TensorBoard separado. Cuando trabaje en un cuaderno, lance el visor antes de iniciar el entrenamiento para monitorizar con TensorBoard.\n",
    "\n",
    "Inicie el visor TensorBoard (Lo sentimos, esto no se muestra en tensorflow.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ot22ujrlLhOd"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyjixlMlBybN"
   },
   "source": [
    "Puede ver los [resultados de una ejecucin previa](https://tensorboard.dev/experiment/lZ0C6FONROaUMfjYkVyJqw) de este bloc de notas en [TensorBoard.dev](https://tensorboard.dev/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0-8Bzg22ox"
   },
   "source": [
    "Por ltimo, ejecute el bucle de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1zZmKmvOH85"
   },
   "outputs": [],
   "source": [
    "fit(train_dataset, test_dataset, steps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMTm4peo3cem"
   },
   "source": [
    "La interpretacin de los registros es ms sutil cuando se entrena un GAN (o un cGAN como pix2pix) en comparacin con un modelo sencillo de clasificacin o regresin. Cosas en las que debe fijarse:\n",
    "\n",
    "- Revise que ni el modelo generador ni el discriminador hayan \"ganado\". Si el `gen_gan_loss` o el `disc_loss` se vuelven muy bajos, es un indicador de que este modelo est dominando al otro, y usted no est entrenando correctamente el modelo combinado.\n",
    "- El valor `log(2) = 0.69` es un buen punto de referencia para estas prdidas, ya que indica una perplejidad de 2: el discriminador tiene, por trmino medio, la misma incertidumbre sobre las dos opciones.\n",
    "- Para el `disc_loss`, un valor inferior a `0,69` significa que el discriminador obtiene mejores resultados que el azar en el conjunto combinado de imgenes reales y generadas.\n",
    "- Para el `gen_gan_loss`, un valor inferior a `0,69` significa que el generador lo hace mejor que el azar al momento de engaar al discriminador.\n",
    "- A medida que progresa el entrenamiento, la `gen_l1_loss` debera disminuir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz80bY3aQ1VZ"
   },
   "source": [
    "## Restaure el ltimo punto de verificacin y pruebe la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSSm4kfvJiqv"
   },
   "outputs": [],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4t4x69adQ5xb"
   },
   "outputs": [],
   "source": [
    "# Restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "## Genere algunas imgenes utilizando el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUgSnmy2nqSP"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on a few examples from the test set\n",
    "for inp, tar in test_dataset.take(5):\n",
    "  generate_images(generator, inp, tar)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
